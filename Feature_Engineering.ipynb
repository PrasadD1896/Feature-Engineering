{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D60svomEZoiL"
   },
   "source": [
    "# Feature Engineering: Unlocking the Power of Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "haYKAxksZpk7"
   },
   "source": [
    "Feature engineering is a critical component of the machine learning workflow that involves transforming raw data into meaningful features that can improve the performance of predictive models. It plays a crucial role in extracting relevant information and reducing noise, ultimately enabling the models to capture underlying patterns and make accurate predictions. This article aims to provide an in-depth exploration of feature engineering techniques, ranging from the basic to the advanced, with practical examples and insights into their applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w2IifDX9ZpuC"
   },
   "source": [
    "## Table of Contents:\n",
    "\n",
    "1. The Importance of Feature Engineering\n",
    "\n",
    "\n",
    "2. Basic Feature Engineering Techniques\n",
    "\n",
    "   2.1  Handling Missing Data\n",
    "\n",
    "   2.2 Dealing with Categorical Variables\n",
    "\n",
    "   2.3 Feature Scaling and Normalization\n",
    "\n",
    "   2.4 Binning and Discretization\n",
    "\n",
    "   2.5 Date and Time Features\n",
    "\n",
    "\n",
    "3. Feature Extraction Techniques\n",
    "\n",
    "   3.1 Textual Data\n",
    "\n",
    "   3.2 Image Data\n",
    "\n",
    "   3.3 Audio Data\n",
    "   \n",
    "   3.4 Time Series Data\n",
    "   \n",
    "\n",
    "4. Feature Selection Methods\n",
    "\n",
    "   4.1 Filter Methods\n",
    "\n",
    "   4.2 Wrapper Methods\n",
    "\n",
    "   4.3 Embedded Methods\n",
    "   \n",
    "\n",
    "5. Feature Construction Techniques\n",
    "   \n",
    "   5.1 Polynomial Features\n",
    "   \n",
    "   5.2 Interaction Terms\n",
    "   \n",
    "   5.3 Domain-Specific Feature Engineering\n",
    "   \n",
    "   5.4 Feature Scaling Revisited\n",
    "   \n",
    "   \n",
    "6. Feature Encoding Methods\n",
    "\n",
    "   6.1 One-Hot Encoding\n",
    "\n",
    "   6.2 Label Encoding\n",
    "\n",
    "   6.3 Target Encoding\n",
    "\n",
    "   6.4 Frequency Encoding\n",
    "   \n",
    "   \n",
    "7. Handling Imbalanced Data\n",
    "   \n",
    "   7.1 Undersampling\n",
    "   \n",
    "   7.2 Oversampling\n",
    "   \n",
    "   7.3 Synthetic Minority Over-sampling Technique (SMOTE)\n",
    "   \n",
    "   \n",
    "8. Feature Engineering for Time Series Data\n",
    "   \n",
    "   8.1 Lagged Features\n",
    "   \n",
    "   8.2 Rolling and Expanding Window Statistics\n",
    "   \n",
    "   8.3 Time-based Features\n",
    "   \n",
    "   \n",
    "9. Advanced Feature Engineering Techniques\n",
    "   \n",
    "   9.1 Feature Embeddings\n",
    "   \n",
    "   9.2 Dimensionality Reduction Techniques\n",
    "   \n",
    "   9.3 Feature Importance and Selection with Tree-Based Models\n",
    "   \n",
    "   9.4 Automated Feature Engineering with AutoML\n",
    "   \n",
    "   \n",
    "10. Evaluating the Impact of Feature Engineering\n",
    "\n",
    "\n",
    "11. Challenges and Best Practices in Feature Engineering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aIQ7krcPZpyT"
   },
   "source": [
    "## 1. The Importance of Feature Engineering:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BqSQEPbUZp2K"
   },
   "source": [
    "Feature engineering plays a crucial role in the success of machine learning models. It involves transforming raw data into meaningful and informative features that capture the underlying patterns and relationships within the data. While advancements in algorithms and computing power have garnered significant attention, feature engineering remains a fundamental and essential step in the machine learning pipeline. This article will explore the importance of feature engineering and its impact on model performance and predictive accuracy.\n",
    "\n",
    "1. Enhanced Representation of Data:\n",
    "Raw data often contains noise, irrelevant information, or missing values. By carefully engineering features, we can extract the most relevant information from the data, reducing noise and capturing the essential characteristics that drive the target variable. This process allows us to create a more focused and informative representation of the data, enabling machine learning models to learn meaningful patterns and make accurate predictions.\n",
    "\n",
    "\n",
    "2. Improved Model Performance:\n",
    "Feature engineering has a direct impact on model performance. Well-engineered features can lead to better discrimination between classes, improved separability of data points, and reduced model bias. By selecting or creating features that are highly correlated with the target variable, we can enhance the model's ability to capture the underlying patterns and relationships in the data, resulting in higher predictive accuracy.\n",
    "\n",
    "\n",
    "3. Handling of Missing Data and Outliers:\n",
    "Missing data and outliers are common challenges in real-world datasets. Feature engineering techniques provide mechanisms to handle these issues effectively. Through imputation methods, missing values can be estimated based on other features, ensuring the preservation of valuable information. Additionally, feature engineering can include outlier detection and treatment, allowing for the identification and handling of outliers that may otherwise disrupt the learning process and adversely impact model performance.\n",
    "\n",
    "\n",
    "4. Encoding Categorical Variables:\n",
    "Categorical variables pose unique challenges in machine learning, as algorithms typically operate on numerical data. Feature engineering techniques, such as one-hot encoding, label encoding, or target encoding, enable the transformation of categorical variables into numerical representations that can be effectively utilized by machine learning algorithms. By appropriately encoding categorical variables, we can unlock the predictive power of these features and harness their contribution to model performance.\n",
    "\n",
    "\n",
    "5. Extraction of Domain-Specific Knowledge:\n",
    "Feature engineering allows the incorporation of domain-specific knowledge into the modeling process. Domain experts can leverage their understanding of the problem and the underlying data to engineer features that capture relevant aspects of the domain. This not only improves the interpretability of the model but also enhances its performance by leveraging insights and patterns specific to the problem domain.\n",
    "\n",
    "\n",
    "6. Handling of Complex Relationships:\n",
    "Feature engineering enables the creation of new features by combining or transforming existing ones. This allows the capture of complex relationships that may not be apparent in the raw data. By incorporating interactions, ratios, or transformations of features, we can model non-linear relationships, capture higher-order interactions, and represent complex dependencies between variables, leading to improved model performance.\n",
    "\n",
    "\n",
    "7. Reducing Dimensionality and Overfitting:\n",
    "Feature engineering plays a crucial role in reducing dimensionality and combating overfitting, particularly when dealing with high-dimensional datasets. Dimensionality reduction techniques, such as PCA or feature selection methods, can be applied to identify the most informative features and discard redundant or irrelevant ones. By reducing the feature space, we mitigate the risk of overfitting, improve computational efficiency, and enhance the generalization capability of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Lhl3fGEbRyI"
   },
   "source": [
    "## 2. Basic Feature Engineering Techniques:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GUCK_hl6bR2f"
   },
   "source": [
    "Feature engineering encompasses a range of techniques that transform raw data into meaningful features for machine learning models. In this section, we will explore several fundamental techniques that form the building blocks of feature engineering. These techniques include handling missing data, dealing with categorical variables, feature scaling and normalization, binning and discretization, and extracting date and time features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GIzEA53UbR5y"
   },
   "source": [
    "### 2.1 Handling Missing Data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wjfmkRNEbSAY"
   },
   "source": [
    "Missing data is a common occurrence in real-world datasets and can significantly impact model performance if not addressed properly. Here are some techniques to handle missing data:\n",
    "\n",
    "### a) Deletion:\n",
    "\n",
    "In cases where the missing values are few and randomly distributed, you can choose to delete the corresponding rows or columns. However, this approach should be used with caution, as it can lead to information loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gtPuow2gZnkw",
    "outputId": "f70d3169-dd05-4a6a-9f78-42a8ee77a062"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B     C\n",
      "3  4.0  8.0  12.0\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: [0, 1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Create a DataFrame with missing values\n",
    "data = {'A': [1, 2, None, 4],\n",
    "        'B': [5, None, 7, 8],\n",
    "        'C': [None, 10, 11, 12]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Drop rows with missing values\n",
    "df_without_missing = df.dropna()\n",
    "\n",
    "print(df_without_missing)\n",
    "\n",
    "# Drop columns with missing values\n",
    "df_without_missing_columns = df.dropna(axis=1)\n",
    "\n",
    "print(df_without_missing_columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hVM4vzhybSDk"
   },
   "source": [
    "### b) Imputation: \n",
    "\n",
    "Missing values can be replaced with estimated values. Simple imputation methods include mean, median, or mode imputation, where missing values are replaced with the mean, median, or mode of the respective feature. Another approach is to use regression imputation, where missing values are predicted based on other features using regression models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z5fxtZqSdTdh",
    "outputId": "3e69ceae-4a2c-4872-cd2c-86c17e4a99fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          A         B     C\n",
      "0  1.000000  5.000000  11.0\n",
      "1  2.000000  6.666667  10.0\n",
      "2  2.333333  7.000000  11.0\n",
      "3  4.000000  8.000000  12.0\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame with missing values\n",
    "data = {'A': [1, 2, None, 4],\n",
    "        'B': [5, None, 7, 8],\n",
    "        'C': [None, 10, 11, 12]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Impute missing values with mean\n",
    "df_imputed = df.fillna(df.mean())\n",
    "\n",
    "print(df_imputed)\n",
    "\n",
    "# Impute missing values with median\n",
    "# df_imputed = df.fillna(df.median())\n",
    "\n",
    "# Impute missing values with a constant value\n",
    "# df_imputed = df.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zqis_4xbhJAs"
   },
   "source": [
    "### c) Indicator Variables: \n",
    "\n",
    "For categorical features, you can create an additional binary feature indicating whether the value was missing or not. This preserves the information about missingness and allows the model to learn patterns associated with missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tflaD4kxhM5n",
    "outputId": "0782697c-cb14-40ab-cb55-1d6cacbbe4e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Color_Blue  Color_Red  Size_Large  Size_Medium  Size_Small\n",
      "0           0          1           0            0           1\n",
      "1           1          0           0            1           0\n",
      "2           0          0           1            0           0\n",
      "3           0          1           0            0           0\n",
      "4           1          0           0            0           1\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Create a DataFrame with missing values\n",
    "data = {'Color': ['Red', 'Blue', None, 'Red', 'Blue'],\n",
    "        'Size': ['Small', 'Medium', 'Large', None, 'Small']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Create indicator variables using get_dummies()\n",
    "indicator_variables = pd.get_dummies(df)\n",
    "\n",
    "# Perform imputation using SimpleImputer\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "imputed_values = imputer.fit_transform(indicator_variables)\n",
    "\n",
    "# Convert the imputed values back to a DataFrame\n",
    "imputed_df = pd.DataFrame(imputed_values, columns=indicator_variables.columns)\n",
    "\n",
    "print(imputed_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xRdYKuO0jzFR"
   },
   "source": [
    "## 2.2 Dealing with Categorical Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "54zwvjydjzB5"
   },
   "source": [
    "Categorical variables represent qualitative characteristics and require special treatment during feature engineering. Here are some techniques for handling categorical variables:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GVrxO3Zuj_OZ"
   },
   "source": [
    "### a) One-Hot Encoding:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dQY_TFGUkFhx"
   },
   "source": [
    " In this approach, each category of a categorical variable is transformed into a binary feature. For example, if a variable \"color\" has categories \"red,\" \"blue,\" and \"green,\" it would be encoded as three separate binary features: \"color_red,\" \"color_blue,\" and \"color_green.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j6Sbegl1kH45",
    "outputId": "8e07e811-6c8b-4e6a-ac27-f4f38644e1ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Color_Blue  Color_Green  Color_Red  Size_Large  Size_Medium  Size_Small\n",
      "0           0            0          1           0            0           1\n",
      "1           1            0          0           0            1           0\n",
      "2           0            1          0           1            0           0\n",
      "3           0            0          1           0            1           0\n",
      "4           1            0          0           0            0           1\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame with categorical variables\n",
    "data = {'Color': ['Red', 'Blue', 'Green', 'Red', 'Blue'],\n",
    "        'Size': ['Small', 'Medium', 'Large', 'Medium', 'Small']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Perform one-hot encoding using get_dummies()\n",
    "one_hot_encoded = pd.get_dummies(df)\n",
    "\n",
    "print(one_hot_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wLlL4ALUj-6n"
   },
   "source": [
    "### b) Label Encoding:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2jE8RBHUj--f"
   },
   "source": [
    "Label encoding assigns a unique numerical label to each category of a categorical variable. However, this method introduces an implicit ordering among categories, which may mislead the model. It is typically suitable for ordinal variables where the order matters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BD4-vItQl_dG",
    "outputId": "3de6cef1-8fe5-44b8-9984-d9e3303940ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 0 1 2 0]\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Create a list with categorical variables\n",
    "colors = ['Red', 'Blue', 'Green', 'Red', 'Blue']\n",
    "\n",
    "# Initialize the LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Perform label encoding\n",
    "encoded_colors = label_encoder.fit_transform(colors)\n",
    "\n",
    "print(encoded_colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8zQqJzUmmVcw"
   },
   "source": [
    "### c) Target Encoding: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zBaBZwL5nTP7"
   },
   "source": [
    "Target encoding replaces each category with the mean target value of the corresponding category. This technique can be useful when there is a correlation between the categorical variable and the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lUZq2_9nmMym",
    "outputId": "e7ae4ae0-3898-47d4-933f-5e2aeddb19eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  category  target  category_target_encoded\n",
      "0        A       1                        1\n",
      "1        B       0                        1\n",
      "2        A       1                        1\n",
      "3        C       0                        0\n",
      "4        B       1                        0\n",
      "5        C       0                        0\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Sample dataset with a categorical feature 'category' and a target variable 'target'\n",
    "data = pd.DataFrame({\n",
    "    'category': ['A', 'B', 'A', 'C', 'B', 'C'],\n",
    "    'target': [1, 0, 1, 0, 1, 0]\n",
    "})\n",
    "\n",
    "# Create a new column to store the target-encoded values\n",
    "data['category_target_encoded'] = 0\n",
    "\n",
    "# Perform target encoding using K-fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "for train_index, val_index in kf.split(data):\n",
    "    train_data = data.iloc[train_index]\n",
    "    val_data = data.iloc[val_index]\n",
    "    \n",
    "    # Calculate the mean target value for each category in the training set\n",
    "    category_mean = train_data.groupby('category')['target'].mean()\n",
    "    \n",
    "    # Map the mean target values to the corresponding categories in the validation set\n",
    "    val_data['category_target_encoded'] = val_data['category'].map(category_mean)\n",
    "    \n",
    "    # Update the target-encoded values in the main dataset\n",
    "    data.iloc[val_index] = val_data\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NWvUKhkHmVgW"
   },
   "source": [
    "### d) Frequency Encoding: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FcHMy73JmV7w"
   },
   "source": [
    "Frequency encoding replaces each category with its frequency in the dataset. It can capture the information about the distribution of categories, especially when certain categories occur more frequently than others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QIY9i9MlnR2w",
    "outputId": "e9e9fb80-4ee8-4fc4-83c1-b98d4c65e557"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  category  category_frequency_encoded\n",
      "0        A                    0.333333\n",
      "1        B                    0.333333\n",
      "2        A                    0.333333\n",
      "3        C                    0.333333\n",
      "4        B                    0.333333\n",
      "5        C                    0.333333\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Sample dataset with a categorical feature 'category'\n",
    "data = pd.DataFrame({\n",
    "    'category': ['A', 'B', 'A', 'C', 'B', 'C']\n",
    "})\n",
    "\n",
    "# Calculate the frequency of each category in the dataset\n",
    "category_counts = data['category'].value_counts()\n",
    "\n",
    "# Create a new column to store the frequency-encoded values\n",
    "data['category_frequency_encoded'] = data['category'].map(category_counts) / len(data)\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ZrJ0TFjnhWO"
   },
   "source": [
    "## 2.3 Feature Scaling and Normalization:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uTfdHRS3nhZS"
   },
   "source": [
    "Feature scaling ensures that all features are on a similar scale, preventing some features from dominating others during model training. Common techniques for feature scaling include:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5rArF_QPnhc0"
   },
   "source": [
    "### a) Standardization:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P1qUT-bknn8d"
   },
   "source": [
    "Standardization scales the features to have zero mean and unit variance. It subtracts the mean and divides by the standard deviation of each feature. This technique is suitable when the features are normally distributed or have outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4vm102WRpUfX",
    "outputId": "7f1cb374-cf64-4518-95fc-04e28221cdf2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.41421356 -0.85361006]\n",
      " [-0.70710678 -0.74757154]\n",
      " [ 0.         -0.6150234 ]\n",
      " [ 0.70710678  0.44536177]\n",
      " [ 1.41421356  1.77084323]]\n",
      "[[2.12132034 3.0963247 ]\n",
      " [2.82842712 4.42180616]\n",
      " [3.53553391 5.74728762]]\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame with numerical features\n",
    "data = {'Feature1': [10, 20, 30, 40, 50],\n",
    "        'Feature2': [0.001, 0.005, 0.01, 0.05, 0.1]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Perform standardization\n",
    "standardized_features = scaler.fit_transform(df)\n",
    "\n",
    "print(standardized_features)\n",
    "\n",
    "new_data = {'Feature1': [60, 70, 80],\n",
    "            'Feature2': [0.15, 0.2, 0.25]}\n",
    "new_df = pd.DataFrame(new_data)\n",
    "\n",
    "# Apply the same standardization to new data\n",
    "standardized_new_features = scaler.transform(new_df)\n",
    "\n",
    "print(standardized_new_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MjwnuL9spxI7"
   },
   "source": [
    "The new data is transformed using the mean and standard deviation computed from the original data. Remember to fit the scaler on the training data and then use the same scaler to transform both the training and testing data to ensure consistency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "53P3dd96noAd"
   },
   "source": [
    "### b) Min-Max Scaling:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6RUYXIKuns0q"
   },
   "source": [
    "Min-max scaling scales the features to a specific range, typically between 0 and 1. It subtracts the minimum value and divides by the difference between the maximum and minimum values. Min-max scaling preserves the original distribution and is suitable when the features have a bounded range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oy_NGKhSnv3i",
    "outputId": "fbc576b6-289e-4d82-9632-8948571db166"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.        ]\n",
      " [0.25       0.04040404]\n",
      " [0.5        0.09090909]\n",
      " [0.75       0.49494949]\n",
      " [1.         1.        ]]\n",
      "[[1.25       1.50505051]\n",
      " [1.5        2.01010101]\n",
      " [1.75       2.51515152]]\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame with numerical features\n",
    "data = {'Feature1': [10, 20, 30, 40, 50],\n",
    "        'Feature2': [0.001, 0.005, 0.01, 0.05, 0.1]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Initialize the MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Perform Min-Max scaling\n",
    "scaled_features = scaler.fit_transform(df)\n",
    "\n",
    "print(scaled_features)\n",
    "\n",
    "new_data = {'Feature1': [60, 70, 80],\n",
    "            'Feature2': [0.15, 0.2, 0.25]}\n",
    "new_df = pd.DataFrame(new_data)\n",
    "\n",
    "# Apply the same Min-Max scaling to new data\n",
    "scaled_new_features = scaler.transform(new_df)\n",
    "\n",
    "print(scaled_new_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w3rcK8USqC8m"
   },
   "source": [
    "The new data is transformed using the minimum and maximum values computed from the original data. Remember to fit the scaler on the training data and then use the same scaler to transform both the training and testing data to ensure consistency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J1tzjxeXqQLQ"
   },
   "source": [
    "### c) Normalization by Vector Norms:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tx6NN_QQqQPK"
   },
   "source": [
    "Normalization by Vector Norms scales each sample (row) in a dataset to have a unit norm. The norm can be calculated using various techniques such as L1 norm (Manhattan norm) or L2 norm (Euclidean norm). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GZM80Kr7qAVc",
    "outputId": "149f3ccf-97eb-4d13-caba-cb7d6fa9df83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9486833  0.31622777]\n",
      " [0.89442719 0.4472136 ]]\n",
      "[[0.85749293 0.51449576]\n",
      " [0.83205029 0.5547002 ]]\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame with numerical features\n",
    "data = {'Feature1': [3, 4],\n",
    "        'Feature2': [1, 2]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Initialize the Normalizer\n",
    "normalizer = Normalizer(norm='l2')\n",
    "\n",
    "# Perform normalization by vector norms\n",
    "normalized_features = normalizer.transform(df)\n",
    "\n",
    "print(normalized_features)\n",
    "\n",
    "new_data = {'Feature1': [5, 6],\n",
    "            'Feature2': [3, 4]}\n",
    "new_df = pd.DataFrame(new_data)\n",
    "\n",
    "# Apply the same normalization to new data\n",
    "normalized_new_features = normalizer.transform(new_df)\n",
    "\n",
    "print(normalized_new_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J7lohGiNqQTT"
   },
   "source": [
    "The new data is normalized using the same norm computed from the original data.\n",
    "Remember to fit the Normalizer on the training data and then use the same Normalizer to transform both the training and testing data to ensure consistency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7CCRIoBYrOKn"
   },
   "source": [
    "## 2.4 Binning and Discretization:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "--Ai_laKr83m"
   },
   "source": [
    "Binning and discretization are techniques used to transform continuous numerical data into categorical or discrete bins. This can be helpful in cases where the exact numerical values are less important than the ranges or categories they fall into."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X3Shnza8rN5Q"
   },
   "source": [
    "### a) Equal-Width Binning: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9yNaRtoDsEW6"
   },
   "source": [
    "This method divides the range of values into equal-width intervals. For example, if a feature ranges from 0 to 100 and you want 5 bins, each bin would cover a range of 20 units (0-20, 20-40, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FgETqpFZsDO5",
    "outputId": "e3d7eb1c-7d09-4c06-f7f3-260181507e0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Feature1  Bin\n",
      "0         2  NaN\n",
      "1         5  0.0\n",
      "2         7  0.0\n",
      "3        10  1.0\n",
      "4        12  1.0\n",
      "5        15  2.0\n",
      "6        18  2.0\n",
      "7        20  2.0\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame with a continuous numerical feature\n",
    "data = {'Feature1': [2, 5, 7, 10, 12, 15, 18, 20]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Define the number of bins and calculate the bin width\n",
    "num_bins = 3\n",
    "bin_width = (df['Feature1'].max() - df['Feature1'].min()) / num_bins\n",
    "\n",
    "# Create the bins\n",
    "bins = [df['Feature1'].min() + i * bin_width for i in range(num_bins + 1)]\n",
    "\n",
    "# Assign values to the bins\n",
    "df['Bin'] = pd.cut(df['Feature1'], bins=bins, labels=False)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RZLlsLxcspHu"
   },
   "source": [
    "The values are assigned to the bins based on the width of each bin. The bin numbers start from 0 and go up to the number of bins minus one.\n",
    "\n",
    "You can adjust the num_bins variable to change the number of bins according to your requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rSElxw7BrypS"
   },
   "source": [
    "### b) Equal-Frequency Binning: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N-F74TCFsHvx"
   },
   "source": [
    "Equal-frequency binning divides the datainto bins such that each bin contains an equal number of data points. This approach ensures that each bin captures a similar amount of information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "09aECV3osPxH",
    "outputId": "7d8259a1-fddc-469c-ee98-10c6d2af6f21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Feature1  Bin\n",
      "0         2  NaN\n",
      "1         5  0.0\n",
      "2         7  0.0\n",
      "3        10  1.0\n",
      "4        12  1.0\n",
      "5        15  2.0\n",
      "6        18  2.0\n",
      "7        20  2.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame with a continuous numerical feature\n",
    "data = {'Feature1': [2, 5, 7, 10, 12, 15, 18, 20]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Define the number of bins\n",
    "num_bins = 3\n",
    "\n",
    "# Calculate the number of values in each bin\n",
    "bin_size = len(df) // num_bins\n",
    "\n",
    "# Sort the values in ascending order\n",
    "df_sorted = df.sort_values('Feature1')\n",
    "\n",
    "# Create the bins\n",
    "bins = [df_sorted['Feature1'].iloc[i * bin_size:(i + 1) * bin_size] for i in range(num_bins)]\n",
    "\n",
    "# Assign values to the bins\n",
    "df['Bin'] = pd.cut(df['Feature1'], bins=[bin.min() for bin in bins] + [df_sorted['Feature1'].max()], labels=False)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NA4-EhbIs45Z"
   },
   "source": [
    "The values are assigned to the bins based on the frequency of values in each bin. The bin numbers start from 0 and go up to the number of bins minus one.\n",
    "\n",
    "Note that due to rounding during the calculation of the bin size, the actual number of values in each bin may slightly differ, resulting in uneven bin sizes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LJo1BYe9ryhs"
   },
   "source": [
    "### c) Custom Binning: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JEF55YzCrylX"
   },
   "source": [
    "Custom binning allows you to define specific bin boundaries based on domain knowledge or data characteristics. It enables you to create bins that align with meaningful thresholds or breakpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tT61lCi1sQS8",
    "outputId": "a3b01f09-5a1d-4829-ea48-4d7ba2c8552f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Feature1  Bin\n",
      "0         2  0.0\n",
      "1         5  1.0\n",
      "2         7  1.0\n",
      "3        10  2.0\n",
      "4        12  2.0\n",
      "5        15  3.0\n",
      "6        18  3.0\n",
      "7        20  NaN\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame with a continuous numerical feature\n",
    "data = {'Feature1': [2, 5, 7, 10, 12, 15, 18, 20]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Define custom bin boundaries\n",
    "bin_boundaries = [0, 5, 10, 15, 20]\n",
    "\n",
    "# Assign values to the bins\n",
    "df['Bin'] = pd.cut(df['Feature1'], bins=bin_boundaries, labels=False, right=False)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lUCWv5e_rOB6"
   },
   "source": [
    "The values are assigned to the bins based on the specified custom bin boundaries. The bin numbers start from 0 and go up to the number of bins minus one.\n",
    "\n",
    "You can define your own custom bin boundaries in the bin_boundaries list according to your specific requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jaZvOAgBtdyy"
   },
   "source": [
    "## 2.5 Date and Time Features:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ktkXLnR8td7M"
   },
   "source": [
    "When working with datasets that include date and time information, extracting relevant features can be beneficial. Here are some common techniques for feature engineering with date and time data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oHtvMh1ZteE6"
   },
   "source": [
    "### a) Extracting Date Components: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K2VCJ2OYuSKG"
   },
   "source": [
    "You can extract various components from date and time, such as year, month, day, day of the week, hour, minute, and second. These components can capture seasonality, temporal patterns, and trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IYciMHrjuSUh",
    "outputId": "fa268e51-09d6-44b8-dc2b-048c765e829a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date  Year  Month  Day  Weekday  Quarter\n",
      "0 2023-05-08  2023      5    8        0        2\n",
      "1 2023-06-15  2023      6   15        3        2\n",
      "2 2023-07-22  2023      7   22        5        3\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame with a date or timestamp column\n",
    "data = {'Date': ['2023-05-08', '2023-06-15', '2023-07-22']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Convert the column to datetime type\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Extract year, month, day, weekday, and quarter\n",
    "df['Year'] = df['Date'].dt.year\n",
    "df['Month'] = df['Date'].dt.month\n",
    "df['Day'] = df['Date'].dt.day\n",
    "df['Weekday'] = df['Date'].dt.weekday\n",
    "df['Quarter'] = df['Date'].dt.quarter\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BNe6GgoUumPB"
   },
   "source": [
    "Each date component is extracted and added as a separate column in the DataFrame.\n",
    "\n",
    "You can also extract other date components such as hour, minute, second, and more using the dt accessor and the corresponding attributes (e.g., dt.hour, dt.minute, dt.second).\n",
    "\n",
    "Make sure to convert the date column to the datetime type before using the dt accessor to access date components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YhL80zf6tsPZ"
   },
   "source": [
    "### b) Time Since a Reference Point: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kcbgFQgVus7X"
   },
   "source": [
    "Calculating the time difference between a specific date/time and a reference point can be useful. For example, you can calculate the number of days between a transaction date and the current date.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3v78mm-AutN0",
    "outputId": "47049b7a-f7a4-4ebe-8bc5-8f59883736da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date TimeElapsed\n",
      "0 2023-05-08    127 days\n",
      "1 2023-06-15    165 days\n",
      "2 2023-07-22    202 days\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame with a date or timestamp column\n",
    "data = {'Date': ['2023-05-08', '2023-06-15', '2023-07-22']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Convert the column to datetime type\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Specify the reference point\n",
    "reference_point = pd.to_datetime('2023-01-01')\n",
    "\n",
    "# Calculate the time difference\n",
    "df['TimeElapsed'] = df['Date'] - reference_point\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Ml8udBzutaA"
   },
   "source": [
    "You can access different components of the timedelta object, such as days, seconds, minutes, and more, using attributes like df['TimeElapsed'].dt.days, df['TimeElapsed'].dt.seconds, df['TimeElapsed'].dt.minutes, etc.\n",
    "\n",
    "Remember to convert the date column to the datetime type before performing the time difference calculation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pxg4LrQqtsUO"
   },
   "source": [
    "### c) Periodicity and Cyclical Encoding:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2NVbvPS5vRvz"
   },
   "source": [
    "For cyclic features like month or day of the week, encoding them as cyclical variables can preserve their periodic nature. This can be done using techniques such as sine-cosine encoding, where the feature is transformed into two new features representing the cyclic pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y6VHSVoXvR59",
    "outputId": "de190027-c499-4381-ab0e-ff9b40b4affe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Hour      Hour_sin      Hour_cos\n",
      "0     1  2.588190e-01  9.659258e-01\n",
      "1     6  1.000000e+00  6.123234e-17\n",
      "2    12  1.224647e-16 -1.000000e+00\n",
      "3    18 -1.000000e+00 -1.836970e-16\n",
      "4    23 -2.588190e-01  9.659258e-01\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create a DataFrame with a cyclical feature (e.g., hour of the day)\n",
    "data = {'Hour': [1, 6, 12, 18, 23]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Perform cyclical encoding\n",
    "df['Hour_sin'] = np.sin(2 * np.pi * df['Hour'] / 24)\n",
    "df['Hour_cos'] = np.cos(2 * np.pi * df['Hour'] / 24)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hfFBGFAnvSCx"
   },
   "source": [
    "The 'Hour_sin' column captures the cyclic pattern of the hour of the day as a sine function, while the 'Hour_cos' column captures it as a cosine function.\n",
    "\n",
    "Cyclical encoding preserves the cyclic nature of the feature and ensures that values on opposite ends of the cycle are close in the encoded space (e.g., 23 and 1 in the example).\n",
    "\n",
    "You can apply cyclical encoding to other cyclical features, such as day of the week, month of the year, or any other periodic feature, by adjusting the formula accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XsVFaaUutsX7"
   },
   "source": [
    "### d) Time-based Aggregations: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MYS0xlS4vSql"
   },
   "source": [
    "Aggregating data based on time intervals (e.g., hourly, daily, weekly) and computing statistics such as mean, median, or count can capture temporal patterns and summarize the data at different granularities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UBGJmdhfvSy_",
    "outputId": "1391e7e1-a468-4b1d-d9fe-555ee633e2aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Value\n",
      "Timestamp                 \n",
      "2023-05-08 10:00:00   17.5\n",
      "2023-05-08 11:00:00   32.5\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame with a datetime column and a numerical column\n",
    "data = {'Timestamp': ['2023-05-08 10:00:00', '2023-05-08 10:15:00', '2023-05-08 10:30:00',\n",
    "                      '2023-05-08 10:45:00', '2023-05-08 11:00:00', '2023-05-08 11:15:00'],\n",
    "        'Value': [10, 15, 20, 25, 30, 35]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Convert the 'Timestamp' column to datetime type\n",
    "df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "\n",
    "# Set the 'Timestamp' column as the index\n",
    "df.set_index('Timestamp', inplace=True)\n",
    "\n",
    "# Resample the DataFrame to hourly frequency and calculate the mean value\n",
    "df_hourly = df.resample('H').mean()\n",
    "\n",
    "print(df_hourly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W_taeSK5vS8R"
   },
   "source": [
    "The values in the 'Value' column are the mean values calculated for each hour.\n",
    "\n",
    "You can perform various aggregations, such as sum, count, minimum, maximum, etc., by applying the corresponding aggregation functions after resampling, like df.resample('H').sum(), df.resample('H').count(), df.resample('H').min(), df.resample('H').max(), etc.\n",
    "\n",
    "Make sure to set the datetime column as the index before using the resample() function for time-based aggregations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pqX_5SsrtsbZ"
   },
   "source": [
    "## 3. Feature Extraction Techniques:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zUxqP-5jw1gS"
   },
   "source": [
    "Feature extraction is a process in which meaningful and representative features are derived from raw data. It involves transforming the data into a more compact and informative representation that captures the underlying patterns and structures. This article explores various feature extraction techniques commonly used in machine learning and data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SSEMo-JAw1jY"
   },
   "source": [
    "## a) Textual Data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zAtjTg5tw1nA"
   },
   "source": [
    "Textual data is abundant in various domains, such as natural language processing, sentiment analysis, information retrieval, and text classification. Extracting meaningful features from text is crucial for effectively representing and analyzing textual data. This article explores several techniques for feature extraction from textual data to enable accurate and efficient analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jWl9s_DDxyl5"
   },
   "source": [
    "### I) Bag-of-Words (BoW):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jY3Fa0erxyt1"
   },
   "source": [
    "The bag-of-words model represents text as a collection of unique words and their frequencies. Each document is transformed into a vector, where each element corresponds to the count or presence of a particular word in the document. The BoW model ignores word order and considers only the occurrence of words. It is a simple yet effective feature extraction technique widely used in text classification, information retrieval, and sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4jRzu2_Ex6rs",
    "outputId": "ea8679d0-95b7-462c-f141-984b19d9dc60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'this': 8, 'is': 3, 'the': 6, 'first': 2, 'document': 1, 'second': 5, 'and': 0, 'third': 7, 'one': 4}\n",
      "[[0 1 1 1 0 0 1 0 1]\n",
      " [0 2 0 1 0 1 1 0 1]\n",
      " [1 0 0 1 1 0 1 1 1]\n",
      " [0 1 1 1 0 0 1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "# Importing Required Libraries\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Create a corpus of documents\n",
    "corpus = ['This is the first document.',\n",
    "          'This document is the second document.',\n",
    "          'And this is the third one.',\n",
    "          'Is this the first document?']\n",
    "\n",
    "# Initialize the CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit the vectorizer on the corpus\n",
    "vectorizer.fit(corpus)\n",
    "\n",
    "# Transform the corpus into a matrix of token counts\n",
    "X = vectorizer.transform(corpus)\n",
    "\n",
    "# Print the vocabulary of the vectorizer\n",
    "print(vectorizer.vocabulary_)\n",
    "\n",
    "# Print the matrix of token counts\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6bmSZHKcy7Uw"
   },
   "source": [
    "In this example, we have a list of documents stored in the documents variable. We create an instance of CountVectorizer, which is a scikit-learn class that helps us convert text documents into a BoW representation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NtnSmLcryjCd"
   },
   "source": [
    "Note that before using the BoW representation for further analysis or modeling, it may be necessary to preprocess the text data by removing punctuation, converting to lowercase, handling stop words, and applying stemming or lemmatization, depending on the specific requirements of your task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LKQYYrmP22J6"
   },
   "source": [
    "### II) Term Frequency-Inverse Document Frequency (TF-IDF):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Chu6kPte22eh"
   },
   "source": [
    "TF-IDF measures the importance of a word in a document relative to its frequency across a corpus. It assigns higher weights to words that are more specific to a particular document but occur less frequently in the corpus. TF-IDF takes into account both the term frequency (TF) and the inverse document frequency (IDF) to create a vector representation of each document. It helps in capturing the discriminative power of words and is commonly used in text classification, information retrieval, and keyword extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YsH9WRcgyOp0",
    "outputId": "2cf9cd42-f094-4111-e120-a76e4c076349"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF representation:\n",
      "[[0.         0.         0.32274454 0.         0.         0.54645401\n",
      "  0.         0.54645401 0.         0.         0.54645401 0.        ]\n",
      " [0.         0.47952794 0.28321692 0.         0.47952794 0.\n",
      "  0.47952794 0.         0.         0.47952794 0.         0.        ]\n",
      " [0.47952794 0.         0.28321692 0.47952794 0.         0.\n",
      "  0.         0.         0.47952794 0.         0.         0.47952794]]\n",
      "\n",
      "Feature names:\n",
      "['enjoy' 'favorite' 'football' 'friends' 'is' 'love' 'my' 'play' 'playing'\n",
      " 'sport' 'to' 'with']\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Sample documents\n",
    "documents = [\n",
    "    \"I love to play football\",\n",
    "    \"Football is my favorite sport\",\n",
    "    \"I enjoy playing football with friends\"\n",
    "]\n",
    "\n",
    "# Create an instance of TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit the vectorizer on the documents and transform the documents into a TF-IDF representation\n",
    "tfidf_representation = vectorizer.fit_transform(documents)\n",
    "\n",
    "# Get the feature names (words) from the vectorizer\n",
    "feature_names = vectorizer.get_feature_names_out() \n",
    "\n",
    "# Print the TF-IDF representation and feature names\n",
    "print(\"TF-IDF representation:\")\n",
    "print(tfidf_representation.toarray())\n",
    "print(\"\\nFeature names:\")\n",
    "print(feature_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5w508a044fWn"
   },
   "source": [
    "In this example, we have a list of documents stored in the documents variable. We create an instance of TfidfVectorizer, which is a scikit-learn class that helps us convert text documents into a TF-IDF representation.\n",
    "\n",
    "The output will display the TF-IDF representation as a matrix, where each row corresponds to a document and each column corresponds to a word. The values in the matrix represent the TF-IDF scores. The feature names will display the vocabulary of words used in the documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qmUI8GLQ4gNn"
   },
   "source": [
    "### III) Word Embeddings:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XwfgRtZ84gQ_"
   },
   "source": [
    "Word embeddings represent words as dense vectors in a continuous space, capturing semantic and syntactic relationships between words. Popular word embedding techniques include Word2Vec, GloVe, and FastText. Word embeddings encode semantic meaning and contextual information, enabling more nuanced and meaningful feature representations. They have revolutionized various natural language processing tasks such as text classification, sentiment analysis, and language translation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nh8wDW2k3f2o",
    "outputId": "2fb99936-783e-46f3-e54b-0ad39b95720a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensionality of word embedding: 100\n",
      "Word embedding for football: [-5.3622725e-04  2.3643136e-04  5.1033497e-03  9.0092728e-03\n",
      " -9.3029495e-03 -7.1168090e-03  6.4588725e-03  8.9729885e-03\n",
      " -5.0154282e-03 -3.7633716e-03  7.3805046e-03 -1.5334714e-03\n",
      " -4.5366134e-03  6.5540518e-03 -4.8601604e-03 -1.8160177e-03\n",
      "  2.8765798e-03  9.9187379e-04 -8.2852151e-03 -9.4488179e-03\n",
      "  7.3117660e-03  5.0702621e-03  6.7576934e-03  7.6286553e-04\n",
      "  6.3508903e-03 -3.4053659e-03 -9.4640139e-04  5.7685734e-03\n",
      " -7.5216377e-03 -3.9361035e-03 -7.5115822e-03 -9.3004224e-04\n",
      "  9.5381187e-03 -7.3191668e-03 -2.3337686e-03 -1.9377411e-03\n",
      "  8.0774371e-03 -5.9308959e-03  4.5162440e-05 -4.7537340e-03\n",
      " -9.6035507e-03  5.0072931e-03 -8.7595852e-03 -4.3918253e-03\n",
      " -3.5099984e-05 -2.9618145e-04 -7.6612402e-03  9.6147433e-03\n",
      "  4.9820580e-03  9.2331432e-03 -8.1579173e-03  4.4957981e-03\n",
      " -4.1370760e-03  8.2453608e-04  8.4986202e-03 -4.4621765e-03\n",
      "  4.5175003e-03 -6.7869602e-03 -3.5484887e-03  9.3985079e-03\n",
      " -1.5776526e-03  3.2137157e-04 -4.1406299e-03 -7.6826881e-03\n",
      " -1.5080082e-03  2.4697948e-03 -8.8802696e-04  5.5336617e-03\n",
      " -2.7429771e-03  2.2600652e-03  5.4557943e-03  8.3459532e-03\n",
      " -1.4537406e-03 -9.2081428e-03  4.3705525e-03  5.7178497e-04\n",
      "  7.4419081e-03 -8.1328274e-04 -2.6384138e-03 -8.7530091e-03\n",
      " -8.5655687e-04  2.8265631e-03  5.4014288e-03  7.0526563e-03\n",
      " -5.7031214e-03  1.8588197e-03  6.0888636e-03 -4.7980510e-03\n",
      " -3.1072604e-03  6.7976294e-03  1.6314756e-03  1.8991709e-04\n",
      "  3.4736372e-03  2.1777749e-04  9.6188262e-03  5.0606038e-03\n",
      " -8.9173904e-03 -7.0415605e-03  9.0145587e-04  6.3925339e-03]\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "import gensim\n",
    "\n",
    "# Prepare your training data (a list of sentences or a text file)\n",
    "sentences = [[\"I\", \"love\", \"playing\", \"football\"],\n",
    "             [\"Football\", \"is\", \"my\", \"favorite\", \"sport\"],\n",
    "             [\"I\", \"enjoy\", \"playing\", \"football\", \"with\", \"friends\"]]\n",
    "\n",
    "# Train the Word2Vec model\n",
    "model = gensim.models.Word2Vec(sentences, min_count=1)\n",
    "\n",
    "\n",
    "# Get the word embedding for a specific word\n",
    "word = \"football\"\n",
    "if word in model.wv:\n",
    "    embedding = model.wv[word]\n",
    "else:\n",
    "    embedding = None  # Handle out-of-vocabulary words\n",
    "\n",
    "# Print the dimensionality of the word embedding\n",
    "print(\"Dimensionality of word embedding:\", model.vector_size)\n",
    "\n",
    "# Print the word embedding vector\n",
    "if embedding is not None:\n",
    "    print(\"Word embedding for\", word + \":\", embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AK6CZx5o6usT"
   },
   "source": [
    "### IV) N-grams:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "em9eEzOV6vwh"
   },
   "source": [
    "N-grams are contiguous sequences of N words in a text. By considering word sequences, N-grams capture local contextual information and improve feature representation. Commonly used N-gram models include unigrams (single words), bigrams (two consecutive words), and trigrams (three consecutive words). N-grams are useful for capturing phrase-level information, language modeling, and text classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zm5cRSLU7oH2",
    "outputId": "ef66c3b7-9b8b-49cb-ad65-1e153b8577e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 2 -grams:\n",
      "('I', 'love')\n",
      "('love', 'to')\n",
      "('to', 'play')\n",
      "('play', 'football')\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "from nltk import ngrams\n",
    "\n",
    "# Sample sentence\n",
    "sentence = \"I love to play football\"\n",
    "\n",
    "# Set the value of N for N-grams\n",
    "N = 2\n",
    "\n",
    "# Generate N-grams\n",
    "ngrams_list = list(ngrams(sentence.split(), N))\n",
    "\n",
    "# Print the generated N-grams\n",
    "print(\"Generated\", N, \"-grams:\")\n",
    "for gram in ngrams_list:\n",
    "    print(gram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-xPsQSbN8PpL"
   },
   "source": [
    "In this example, we have a sample sentence stored in the sentence variable. We set the value of N to indicate the desired number of words in each N-gram.\n",
    "\n",
    "The output will display the generated N-grams based on the given sentence and the specified value of N. For example, if N is set to 2, the code will generate and print all the bigrams (2-grams) from the sentence.\n",
    "\n",
    "Note that you need to have the nltk library installed in your Python environment to use the ngrams function. You can install it using pip install nltk if you haven't already. Additionally, you may need to download certain resources such as tokenizers or stopwords from the NLTK data package using nltk.download()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8TgwxTbV6v2w"
   },
   "source": [
    "### V) Text Hashing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wMCrgCBq7Vln"
   },
   "source": [
    "Text hashing techniques, such as the Hashing Trick or Feature Hashing, convert text into fixed-length feature vectors. These techniques use hash functions to map words or word n-grams into a predefined feature space. Text hashing is memory-efficient and allows for fast feature extraction, making it suitable for large-scale text analysis, topic modeling, and text classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CExlx1ZI7okK",
    "outputId": "5e1f17df-ff5c-4b41-9c00-801a1df9e169"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hashed representation:\n",
      "[[ 0.        -0.5        0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.5        0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        -0.5        0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.5        0.         0.         0.         0.\n",
      "   0.         0.         0.         0.       ]\n",
      " [ 0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.4472136  0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.4472136  0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.        -0.4472136\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.4472136\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.4472136  0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.       ]\n",
      " [ 0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.        -0.4472136\n",
      "   0.         0.         0.         0.         0.4472136  0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        -0.4472136  0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.4472136\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.4472136  0.       ]]\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "# Sample documents\n",
    "documents = [\n",
    "    \"I love to play football\",\n",
    "    \"Football is my favorite sport\",\n",
    "    \"I enjoy playing football with friends\"\n",
    "]\n",
    "\n",
    "# Create an instance of HashingVectorizer\n",
    "vectorizer = HashingVectorizer(n_features=100)\n",
    "\n",
    "# Transform the documents into a hashed representation\n",
    "hashed_representation = vectorizer.transform(documents)\n",
    "\n",
    "# Print the hashed representation\n",
    "print(\"Hashed representation:\")\n",
    "print(hashed_representation.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VAILSjUf74Xd"
   },
   "source": [
    "In this example, we have a list of documents stored in the documents variable. We create an instance of HashingVectorizer from sklearn.feature_extraction.text, which is a scikit-learn class for text hashing.\n",
    "\n",
    "The output will display the hashed representation as a matrix, where each row corresponds to a document, and each column corresponds to a feature in the hashed representation. The values in the matrix represent the hashed numerical representations of the words in the documents.\n",
    "\n",
    "Note that unlike other feature extraction techniques like BoW or TF-IDF, text hashing does not preserve the original words or their frequencies. It creates a fixed-length numerical representation based on the hash function and the specified number of features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CyNFoaKf7XXP"
   },
   "source": [
    "### VI) Named Entity Recognition (NER):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nHFZPd6e7atC"
   },
   "source": [
    "Named Entity Recognition is a technique that identifies and classifies named entities in text, such as names of people, organizations, locations, and other specific entities. NER extracts features related to the presence or type of named entities, providing valuable information for tasks such as information extraction, question answering, and document understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SfhdLJ71879J",
    "outputId": "ae026c5f-ac1f-45bf-d754-4e46b2d7083e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Named entities:\n",
      "('Apple Inc.', 'ORG')\n",
      "('Europe', 'LOC')\n",
      "('Asia', 'LOC')\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "import spacy\n",
    "\n",
    "# Load the spaCy English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Sample text\n",
    "text = \"Apple Inc. is looking to expand its business into new markets, including Europe and Asia.\"\n",
    "\n",
    "# Process the text with spaCy\n",
    "doc = nlp(text)\n",
    "\n",
    "# Extract named entities\n",
    "entities = [(entity.text, entity.label_) for entity in doc.ents]\n",
    "\n",
    "# Print the named entities\n",
    "print(\"Named entities:\")\n",
    "for entity in entities:\n",
    "    print(entity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HPc7Czj69ztU"
   },
   "source": [
    "The output will display the named entities found in the text along with their corresponding labels.\n",
    "\n",
    "Note that different models or languages may yield different results, and you can customize the behavior of spaCy by adding additional rules, training your own models, or using other NER libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TzOapZEs7eNU"
   },
   "source": [
    "### VII) Topic Modeling:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j1tfOYNn7hxg"
   },
   "source": [
    "Topic modeling techniques, such as Latent Dirichlet Allocation (LDA) and Non-negative Matrix Factorization (NMF), uncover latent topics in a collection of documents. Topic models represent documents as mixtures of topics, where each topic is a distribution over words. Extracted topics can serve as features, allowing documents to be represented by their topical composition. Topic modeling is beneficial for document clustering, content recommendation, and exploratory analysis of text corpora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0hjFhB4F7po4",
    "outputId": "a6666458-ab39-43e5-a575-5a89357c1f3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.086*\"i\" + 0.083*\"movies\" + 0.051*\"to\" + 0.050*\"my\" + 0.050*\"favorite\"')\n",
      "(1, '0.090*\"football\" + 0.089*\"sport\" + 0.089*\"is\" + 0.054*\"favorite\" + 0.054*\"my\"')\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "\n",
    "# Sample documents\n",
    "documents = [\n",
    "    \"I love to play football\",\n",
    "    \"Football is my favorite sport\",\n",
    "    \"I enjoy playing football with friends\",\n",
    "    \"Basketball is also a great sport\",\n",
    "    \"I like to watch movies\",\n",
    "    \"Movies are my favorite form of entertainment\"\n",
    "]\n",
    "\n",
    "# Preprocess the documents\n",
    "preprocessed_documents = [doc.lower().split() for doc in documents]\n",
    "\n",
    "# Create a dictionary from the preprocessed documents\n",
    "dictionary = corpora.Dictionary(preprocessed_documents)\n",
    "\n",
    "# Create a corpus from the preprocessed documents\n",
    "corpus = [dictionary.doc2bow(doc) for doc in preprocessed_documents]\n",
    "\n",
    "# Train the LDA model\n",
    "lda_model = gensim.models.LdaModel(corpus, num_topics=2, id2word=dictionary, passes=10)\n",
    "\n",
    "# Print the topics\n",
    "topics = lda_model.print_topics(num_words=5)\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7RLActFM-jKo"
   },
   "source": [
    "The output will display the topics along with their associated words and their probabilities.\n",
    "\n",
    "Note that the quality and coherence of the topics may depend on the size and quality of the training corpus, the number of topics chosen, and other tuning parameters. Experimentation and fine-tuning may be required to obtain meaningful and coherent topics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lM8SB3MmAf3P"
   },
   "source": [
    "## 3.2 Image Data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bbhto7cRAf5z"
   },
   "source": [
    "Image data is a type of data that represents visual information in the form of digital images. Images are composed of pixels, with each pixel representing a specific color or intensity value. Analyzing and processing image data is a common task in various fields, including computer vision, machine learning, and image processing. \n",
    "\n",
    "When working with image data, there are several techniques for extracting meaningful information or features from images. Here are some common image data extraction techniques:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9qCj2cQbAf8H"
   },
   "source": [
    "### I) Pixel-based Features:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ReAPA2ddAf-q"
   },
   "source": [
    "1. Color Information: Extracting color features such as RGB values, color histograms, or color moments to capture the color distribution in an image.\n",
    "\n",
    "\n",
    "2. Texture Analysis: Calculating texture features like local binary patterns (LBP), gray-level co-occurrence matrices (GLCM), or Gabor filters to describe the patterns and textures present in an image.\n",
    "\n",
    "\n",
    "3. Intensity and Gradient: Analyzing pixel intensities or gradients using techniques like edge detection or gradient-based feature extraction methods (e.g., Sobel, Canny) to identify image edges or boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Rc5g788O-uq"
   },
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread('image.jpg')\n",
    "\n",
    "# Extract color features\n",
    "rgb_values = image.reshape(-1, 3)  # Reshape the image to a 2D array of RGB values\n",
    "mean_rgb = np.mean(rgb_values, axis=0)  # Compute the mean RGB values\n",
    "std_rgb = np.std(rgb_values, axis=0)  # Compute the standard deviation of RGB values\n",
    "\n",
    "# Extract texture features (LBP)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  # Convert the image to grayscale\n",
    "lbp = cv2.ORB_create()\n",
    "keypoints, descriptors = lbp.detectAndCompute(gray, None)  # Extract keypoints and descriptors\n",
    "num_keypoints = len(keypoints)  # Get the number of keypoints\n",
    "\n",
    "# Extract intensity and gradient features (Edges)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  # Convert the image to grayscale\n",
    "edges = cv2.Canny(gray, 100, 200)  # Apply Canny edge detection\n",
    "num_edges = np.sum(edges)  # Count the number of edge pixels\n",
    "\n",
    "# Print the extracted features\n",
    "print(\"Color Features:\")\n",
    "print(\"Mean RGB:\", mean_rgb)\n",
    "print(\"Standard Deviation RGB:\", std_rgb)\n",
    "\n",
    "print(\"Texture Features:\")\n",
    "print(\"Number of Keypoints:\", num_keypoints)\n",
    "\n",
    "print(\"Intensity and Gradient Features:\")\n",
    "print(\"Number of Edges:\", num_edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5HWVv7x0AgEy"
   },
   "source": [
    "In this code example, I assume that there is an image file named \"image.jpg\" in the current directory.\n",
    "\n",
    "Note that this code snippet provides a basic demonstration of pixel-based feature extraction. Depending on your specific use case, you may need to explore different feature extraction techniques and parameters to achieve the desired results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dskR7uCCPReN"
   },
   "source": [
    "### II) Local Features:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Otsg_IxLPRhv"
   },
   "source": [
    "1. Keypoint Detection: Identifying distinctive keypoints in an image using methods like Scale-Invariant Feature Transform (SIFT), Speeded-Up Robust Features (SURF), or Oriented FAST and Rotated BRIEF (ORB).\n",
    "\n",
    "\n",
    "2. Feature Descriptors: Extracting feature descriptors around keypoints, such as local binary patterns (LBP), histogram of oriented gradients (HOG), or scale-invariant feature descriptors (SIFT descriptors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_kwcrV9RPLe2"
   },
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread('image.jpg')\n",
    "\n",
    "# Convert the image to grayscale\n",
    "image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Initialize the feature detector (e.g., SIFT, SURF, ORB)\n",
    "feature_detector = cv2.SIFT_create()\n",
    "\n",
    "# Detect keypoints and compute descriptors\n",
    "keypoints, descriptors = feature_detector.detectAndCompute(image_gray, None)\n",
    "\n",
    "# Draw keypoints on the image\n",
    "image_keypoints = cv2.drawKeypoints(image, keypoints, None, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "# Display the image with keypoints\n",
    "cv2.imshow('Image with Keypoints', image_keypoints)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Print the number of detected keypoints and the size of the descriptor vector\n",
    "print(\"Number of Keypoints:\", len(keypoints))\n",
    "print(\"Descriptor Size:\", descriptors.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t0ubU1j3P7_k"
   },
   "source": [
    "In this code snippet, I assume that there is an image file named \"image.jpg\" in the current directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V9ybpTjnP8Co"
   },
   "source": [
    "### III) Convolutional Neural Networks (CNN) Features:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mAFmddbtP8GY"
   },
   "source": [
    "1. Transfer Learning: Using pre-trained CNN models like VGG, ResNet, or Inception to extract high-level features from images. These models are trained on large-scale datasets and capture complex image representations.\n",
    " \n",
    " \n",
    "2. Intermediate Layer Features: Extracting features from intermediate layers of a CNN to capture both low-level and high-level image information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NoKYG2FeQnaq"
   },
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "import numpy as np\n",
    "\n",
    "# Load the pre-trained VGG16 model\n",
    "model = VGG16(weights='imagenet', include_top=False)\n",
    "\n",
    "# Load and preprocess the image\n",
    "img_path = 'image.jpg'  # Update with the path to your image\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "# Extract features using the VGG16 model\n",
    "features = model.predict(x)\n",
    "\n",
    "# Flatten the features\n",
    "flatten_features = features.flatten()\n",
    "\n",
    "# Print the shape of the extracted features\n",
    "print(\"Shape of features:\", flatten_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bNYUck2ZQt8T"
   },
   "source": [
    "In this code snippet, I assume that there is an image file named \"image.jpg\" in the current directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LxlbEsy5Qt_Q"
   },
   "source": [
    "### IV) Shape Analysis:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XW7Kq1a6QuEW"
   },
   "source": [
    "1. Contour Detection: Detecting and representing the contours or outlines of objects within an image using techniques like Canny edge detection or contour tracing algorithms.\n",
    "\n",
    "\n",
    "2. Shape Descriptors: Calculating shape descriptors like Hu moments, Fourier descriptors, or Zernike moments to describe the shape characteristics of objects in an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oS24B7Q1RC_w"
   },
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "from skimage import io, measure\n",
    "\n",
    "# Load the binary image\n",
    "image = io.imread('binary_image.png', as_gray=True)\n",
    "\n",
    "# Perform connected component analysis to extract objects\n",
    "labels = measure.label(image, connectivity=2)\n",
    "regions = measure.regionprops(labels)\n",
    "\n",
    "# Print the number of detected objects\n",
    "print(\"Number of objects:\", len(regions))\n",
    "\n",
    "# Iterate over each object and extract shape features\n",
    "for region in regions:\n",
    "    # Extract basic shape properties\n",
    "    centroid = region.centroid\n",
    "    area = region.area\n",
    "    perimeter = region.perimeter\n",
    "    bbox = region.bbox\n",
    "\n",
    "    # Extract more complex shape properties\n",
    "    eccentricity = region.eccentricity\n",
    "    solidity = region.solidity\n",
    "\n",
    "    # Print the shape features\n",
    "    print(\"Centroid:\", centroid)\n",
    "    print(\"Area:\", area)\n",
    "    print(\"Perimeter:\", perimeter)\n",
    "    print(\"Bounding Box:\", bbox)\n",
    "    print(\"Eccentricity:\", eccentricity)\n",
    "    print(\"Solidity:\", solidity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q9lZ6TSbQ-Wh"
   },
   "source": [
    "In this code snippet, I assume that you have a binary image file named binary_image.png in the current directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VIEKEv00RgIs"
   },
   "source": [
    "### V) Image Segmentation:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3WxJLQJ2RgLj"
   },
   "source": [
    "1. Region-based Segmentation: Dividing an image into distinct regions based on color, texture, or intensity properties using techniques like k-means clustering, mean-shift clustering, or graph-based segmentation.\n",
    "\n",
    "\n",
    "2. Semantic Segmentation: Assigning semantic labels to each pixel in an image to distinguish different object classes or regions of interest using deep learning-based segmentation models like U-Net or Fully Convolutional Networks (FCN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7y-P8FaQR8Zj"
   },
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import numpy as np\n",
    "from skimage import io, segmentation\n",
    "from skimage.color import rgb2gray\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the image\n",
    "image = io.imread('image.jpg')\n",
    "\n",
    "# Convert the image to grayscale\n",
    "image_gray = rgb2gray(image)\n",
    "\n",
    "# Initialize the mask\n",
    "mask = np.zeros(image.shape[:2], dtype=np.uint8)\n",
    "\n",
    "# Set the foreground and background regions\n",
    "foreground = (image_gray > 0.5).astype(np.uint8)\n",
    "background = 1 - foreground\n",
    "\n",
    "# Set the initial markers for GrabCut algorithm\n",
    "markers = np.zeros(image.shape[:2], dtype=np.int32)\n",
    "markers[foreground == 1] = 1  # Foreground markers\n",
    "markers[background == 1] = 2  # Background markers\n",
    "\n",
    "# Apply the GrabCut algorithm\n",
    "result = segmentation.grabcut(image, markers, mask)\n",
    "\n",
    "# Extract the segmented foreground mask\n",
    "foreground_mask = np.where((result == 1) + (result == 3), 1, 0)\n",
    "\n",
    "# Display the original image and segmented mask\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axes[0].imshow(image)\n",
    "axes[0].set_title('Original Image')\n",
    "\n",
    "axes[1].imshow(foreground_mask, cmap='gray')\n",
    "axes[1].set_title('Segmented Mask')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u_5ZAZS4R9AC"
   },
   "source": [
    "In this code snippet, I assume that you have a binary image file named binary_image.png in the current directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ACpVi-I1RgPK"
   },
   "source": [
    "### VI) Feature Fusion and Dimensionality Reduction:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cNxKkD5aRx4D"
   },
   "source": [
    "1.  Feature Concatenation: Combining multiple features extracted from different techniques into a single feature vector for further analysis or modeling.\n",
    " \n",
    " \n",
    "2. Principal Component Analysis (PCA): Reducing the dimensionality of feature vectors by projecting them onto a lower-dimensional space while preserving the most important information.\n",
    "\n",
    "\n",
    "3. t-Distributed Stochastic Neighbor Embedding (t-SNE): Visualizing and reducing high-dimensional feature vectors into a lower-dimensional space for exploratory analysis or clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6LYRLln6R98_",
    "outputId": "b1d4c859-a03a-4817-decd-7ad10b00adb7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of fused features: (100, 30)\n",
      "Shape of reduced features: (100, 5)\n"
     ]
    }
   ],
   "source": [
    "# PCA\n",
    "\n",
    "# Import Required Libraries\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Generate dummy feature matrices\n",
    "features1 = np.random.rand(100, 10)  # Features from source 1\n",
    "features2 = np.random.rand(100, 20)  # Features from source 2\n",
    "\n",
    "# Feature fusion using concatenation\n",
    "fusion_features = np.concatenate((features1, features2), axis=1)\n",
    "\n",
    "# Dimensionality reduction using PCA\n",
    "pca = PCA(n_components=5)  # Set the desired number of components\n",
    "reduced_features = pca.fit_transform(fusion_features)\n",
    "\n",
    "# Print the shape of the fused and reduced feature matrices\n",
    "print(\"Shape of fused features:\", fusion_features.shape)\n",
    "print(\"Shape of reduced features:\", reduced_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YvEiv8ZpRx7N"
   },
   "source": [
    "In this code snippet, we generate dummy feature matrices features1 and features2 as placeholders for features from different sources. features1 has shape (100, 10) and features2 has shape (100, 20)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w1MkSmMeTLoV"
   },
   "source": [
    "## 3.3 Audio Data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3eWdprS8TLrV"
   },
   "source": [
    "Audio data holds valuable information that can be harnessed for diverse applications, ranging from speech recognition to music classification. However, raw audio signals are complex and challenging to process directly. Feature extraction plays a vital role in transforming raw audio into a more compact and representative format, enabling efficient analysis and machine learning tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EY5TPzYTUr5t"
   },
   "source": [
    "### I) Preprocessing Audio Signals:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JTjSrZ95TLvy"
   },
   "source": [
    "Before feature extraction, preprocessing steps such as resampling, normalization, and noise reduction are essential. These steps ensure that the audio signals are in a suitable format for subsequent analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-GSoUbCATLD_"
   },
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "# Load the audio file\n",
    "audio_path = 'audio.wav'  # Update with the path to your audio file\n",
    "audio, sr = librosa.load(audio_path)\n",
    "\n",
    "# Resample the audio\n",
    "target_sr = 16000  # Set the desired sampling rate\n",
    "audio_resampled = librosa.resample(audio, sr, target_sr)\n",
    "\n",
    "# Normalize the audio\n",
    "audio_normalized = librosa.util.normalize(audio_resampled)\n",
    "\n",
    "# Apply noise reduction\n",
    "noise_clip = audio_normalized[:5000]  # Select a portion of audio for noise estimation\n",
    "noisy_part = audio_normalized[5000:10000]  # Select a noisy portion of audio for noise reduction\n",
    "noise_mean = np.mean(np.abs(noise_clip))\n",
    "denoised_part = noisy_part * (noise_mean / np.mean(np.abs(noisy_part)))\n",
    "\n",
    "# Combine the denoised part with the rest of the audio\n",
    "audio_denoised = np.concatenate((audio_normalized[:5000], denoised_part, audio_normalized[10000:]))\n",
    "\n",
    "# Save the preprocessed audio\n",
    "output_path = 'preprocessed_audio.wav'  # Update with the desired output path\n",
    "librosa.output.write_wav(output_path, audio_denoised, target_sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZupZkRsyVWfk"
   },
   "source": [
    "In this code snippet, I assume that there is an audio file named audio.wav in the current directory. Adjust the audio_path variable to the correct file path if needed.\n",
    "\n",
    "The code uses the librosa.load function to load the audio file and obtain the audio signal (audio) and the sampling rate (sr).\n",
    "\n",
    "To resample the audio, we specify the desired target sampling rate (target_sr) and use the librosa.resample function to perform the resampling. The resulting resampled audio is stored in the audio_resampled variable.\n",
    "\n",
    "Next, we normalize the audio using the librosa.util.normalize function, which scales the audio signal to have a maximum absolute value of 1. The normalized audio is stored in the audio_normalized variable.\n",
    "\n",
    "To apply noise reduction, we first estimate the noise by selecting a portion of the audio signal (noise_clip) that contains only background noise. Then, we select a noisy portion of the audio (noisy_part) where we want to reduce the noise. We calculate the mean absolute value of the noise clip (noise_mean) and scale the noisy part by the ratio of the noise mean to the mean absolute value of the noisy part. The denoised part is stored in the denoised_part variable.\n",
    "\n",
    "At the end, we combine the denoised part with the rest of the audio by concatenating the three audio segments: the beginning of the original audio, the denoised part, and the remaining portion of the original audio. The resulting preprocessed audio is stored in the audio_denoised variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TsUMnwl5V08U"
   },
   "source": [
    "### II) Time-Domain Features:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4xlrEVzqWWGp"
   },
   "source": [
    "Time-domain features capture characteristics in the amplitude, energy, and temporal aspects of audio signals. Features like amplitude, zero-crossing rate, and energy provide valuable insights into the signal's properties and can be used for tasks like audio segmentation and speech recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cLbMjY_rWfr7"
   },
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import librosa\n",
    "\n",
    "# Load the audio file\n",
    "audio_path = 'audio.wav'  # Update with the path to your audio file\n",
    "audio, sr = librosa.load(audio_path)\n",
    "\n",
    "# Amplitude\n",
    "amplitude = librosa.amplitude_to_db(librosa.stft(audio), ref=np.max)\n",
    "\n",
    "# Zero-crossing rate\n",
    "zero_crossing_rate = librosa.feature.zero_crossing_rate(audio)\n",
    "\n",
    "# Energy\n",
    "energy = librosa.feature.rms(audio)\n",
    "\n",
    "# Print the shape of each feature\n",
    "print(\"Amplitude shape:\", amplitude.shape)\n",
    "print(\"Zero-crossing rate shape:\", zero_crossing_rate.shape)\n",
    "print(\"Energy shape:\", energy.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "51cGH2iTWf1-"
   },
   "source": [
    "In this code snippet, I assume that there is an audio file named audio.wav in the current directory. Adjust the audio_path variable to the correct file path if needed.\n",
    "\n",
    "The code uses the librosa.load function to load the audio file and obtain the audio signal (audio) and the sampling rate (sr).\n",
    "\n",
    "To extract the amplitude, we first compute the Short-Time Fourier Transform (STFT) of the audio signal using the librosa.stft function. Then, we convert the magnitude spectrogram to decibels using the librosa.amplitude_to_db function. This process helps in capturing the amplitude information in a more perceptually meaningful scale. The resulting amplitude feature is stored in the amplitude variable.\n",
    "\n",
    "To calculate the zero-crossing rate, we use the librosa.feature.zero_crossing_rate function, which calculates the rate of sign-changes in the audio signal. The resulting zero-crossing rate feature is stored in the zero_crossing_rate variable.\n",
    "\n",
    "For the energy feature, we use the librosa.feature.rms function, which computes the root mean square (RMS) energy of the audio signal over short windows. The resulting energy feature is stored in the energy variable.\n",
    "\n",
    "At the end, we print the shape of each feature to verify their dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dLLmgA0nV1FH"
   },
   "source": [
    "### III) Frequency-Domain Features:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q3nA5YmRV8DA"
   },
   "source": [
    "Frequency-domain features provide information about the spectral content of audio signals. Techniques like the Fast Fourier Transform (FFT) enable the analysis of signal components at different frequencies. Features such as spectral centroid and spectral flux reveal important spectral characteristics and can aid in tasks like music genre classification and audio event detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tDSodLivWgt8"
   },
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import librosa\n",
    "\n",
    "# Load the audio file\n",
    "audio_path = 'audio.wav'  # Update with the path to your audio file\n",
    "audio, sr = librosa.load(audio_path)\n",
    "\n",
    "# Compute the Short-Time Fourier Transform (STFT)\n",
    "stft = librosa.stft(audio)\n",
    "\n",
    "# Spectral centroid\n",
    "spectral_centroid = librosa.feature.spectral_centroid(S=stft, sr=sr)\n",
    "\n",
    "# Spectral flux\n",
    "spectral_flux = librosa.onset.onset_strength(S=stft)\n",
    "\n",
    "# Print the shape of each feature\n",
    "print(\"Spectral centroid shape:\", spectral_centroid.shape)\n",
    "print(\"Spectral flux shape:\", spectral_flux.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Muz7uctVWg1G"
   },
   "source": [
    "In this code snippet, I assume that there is an audio file named audio.wav in the current directory. Adjust the audio_path variable to the correct file path if needed.\n",
    "\n",
    "The code uses the librosa.load function to load the audio file and obtain the audio signal (audio) and the sampling rate (sr).\n",
    "\n",
    "To extract frequency-domain features, we first compute the Short-Time Fourier Transform (STFT) of the audio signal using the librosa.stft function. This transforms the audio signal from the time domain to the frequency domain, providing information about the spectral content over time.\n",
    "\n",
    "To calculate the spectral centroid, we use the librosa.feature.spectral_centroid function. This feature represents the center of mass of the power spectrum and provides an estimate of the \"brightness\" of the sound. The S parameter in the function is the magnitude spectrogram obtained from the STFT, and sr is the sampling rate of the audio signal. The resulting spectral centroid feature is stored in the spectral_centroid variable.\n",
    "\n",
    "For the spectral flux feature, we use the librosa.onset.onset_strength function, which calculates the spectral flux or the rate of change of the spectrum. This feature measures how much the spectrum of the audio signal changes over time and can be useful for detecting onsets or abrupt changes in the audio. The S parameter in the function is again the magnitude spectrogram obtained from the STFT. The resulting spectral flux feature is stored in the spectral_flux variable and we print the shape of each feature to verify their dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XjuQVD9kV8GQ"
   },
   "source": [
    "### IV) Mel-Frequency Cepstral Coefficients (MFCC):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AFzs7ZyhV8KQ"
   },
   "source": [
    "MFCCs are widely used in audio feature extraction. They capture both spectral and temporal aspects of audio signals by utilizing the Mel scale and the Discrete Cosine Transform (DCT). MFCCs are highly effective in speech and speaker recognition, music genre classification, and acoustic scene analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sEZP4XFLWhiQ"
   },
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import librosa\n",
    "\n",
    "# Load the audio file\n",
    "audio_path = 'audio.wav'  # Update with the path to your audio file\n",
    "audio, sr = librosa.load(audio_path)\n",
    "\n",
    "# Compute the MFCCs\n",
    "mfccs = librosa.feature.mfcc(audio, sr=sr, n_mfcc=13)\n",
    "\n",
    "# Print the shape of the MFCCs\n",
    "print(\"MFCCs shape:\", mfccs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jFAW85qIWhpk"
   },
   "source": [
    "In this code snippet, I assume that there is an audio file named audio.wav in the current directory. Adjust the audio_path variable to the correct file path if needed.\n",
    "\n",
    "The code uses the librosa.load function to load the audio file and obtain the audio signal (audio) and the sampling rate (sr).\n",
    "\n",
    "To compute the MFCCs, we use the librosa.feature.mfcc function. This function takes the audio signal as input, along with the sampling rate (sr) and the number of MFCCs to be computed (n_mfcc). By default, it calculates 20 MFCCs, but you can adjust the n_mfcc parameter to a different value. The resulting MFCCs are stored in the mfccs variable.\n",
    "\n",
    "At the end, we print the shape of the MFCCs to verify their dimensions.\n",
    "\n",
    "You can further customize the code by modifying the parameters of the librosa.feature.mfcc function, such as the number of MFCCs, the window size, and the hop length, to suit your specific requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DTbErM-nV8R_"
   },
   "source": [
    "### V) Chroma Features:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hd4q4TioWEIg"
   },
   "source": [
    "Chroma features focus on the pitch and tonal information of audio signals. They represent the distribution of musical notes across time and are useful in tasks such as music transcription, chord recognition, and melody extraction. Chroma features provide a concise representation of the harmonic content of audio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cM1f4rFAWiKP"
   },
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import librosa\n",
    "\n",
    "# Load the audio file\n",
    "audio_path = 'audio.wav'  # Update with the path to your audio file\n",
    "audio, sr = librosa.load(audio_path)\n",
    "\n",
    "# Compute the chroma features\n",
    "chroma = librosa.feature.chroma_stft(audio, sr=sr)\n",
    "\n",
    "# Print the shape of the chroma features\n",
    "print(\"Chroma features shape:\", chroma.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aKqsxbF9WiQ5"
   },
   "source": [
    "In this code snippet, I assume that there is an audio file named audio.wav in the current directory. Adjust the audio_path variable to the correct file path if needed.\n",
    "\n",
    "The code uses the librosa.load function to load the audio file and obtain the audio signal (audio) and the sampling rate (sr).\n",
    "\n",
    "To compute the chroma features, we use the librosa.feature.chroma_stft function. This function calculates the chromagram, which represents the distribution of pitch classes in the audio signal. It uses the Short-Time Fourier Transform (STFT) to obtain the magnitude spectrogram and then maps the frequencies onto the 12 pitch classes. The resulting chroma features are stored in the chroma variable.\n",
    "\n",
    "At last, we print the shape of the chroma features to verify their dimensions.\n",
    "\n",
    "You can further customize the code by modifying the parameters of the librosa.feature.chroma_stft function, such as the window size, hop length, and the number of chroma bins, to suit your specific requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xBWguK73WELP"
   },
   "source": [
    "### VI) Rhythm and Tempo Features:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J1ZnNe0BWKio"
   },
   "source": [
    "Rhythm and tempo analysis are vital in music-related applications. Beat tracking algorithms detect the temporal structure of music, allowing tasks like tempo estimation, music synchronization, and rhythmic pattern recognition. Tempo features provide insights into the rhythmic characteristics of audio signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aXdNnmj7Wi9j"
   },
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import librosa\n",
    "\n",
    "# Load the audio file\n",
    "audio_path = 'audio.wav'  # Update with the path to your audio file\n",
    "audio, sr = librosa.load(audio_path)\n",
    "\n",
    "# Compute the tempo and beat frames\n",
    "tempo, beat_frames = librosa.beat.beat_track(audio, sr=sr)\n",
    "\n",
    "# Compute the rhythm features\n",
    "rhythm = librosa.feature.tempogram(audio, sr=sr)\n",
    "\n",
    "# Print the tempo and shape of the rhythm features\n",
    "print(\"Tempo:\", tempo)\n",
    "print(\"Rhythm features shape:\", rhythm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "05OP7b6JWKmi"
   },
   "source": [
    "In this code snippet, I assume that there is an audio file named audio.wav in the current directory. Adjust the audio_path variable to the correct file path if needed.\n",
    "\n",
    "The code uses the librosa.load function to load the audio file and obtain the audio signal (audio) and the sampling rate (sr).\n",
    "\n",
    "To compute the tempo, we use the librosa.beat.beat_track function. This function estimates the tempo of the audio signal and returns the tempo in beats per minute (BPM) and the beat frames. The resulting tempo is stored in the tempo variable.\n",
    "\n",
    "To compute the rhythm features, we use the librosa.feature.tempogram function. This function computes the tempogram, which represents the local autocorrelation of the onset strength envelope. It provides information about the rhythmic patterns in the audio signal. The resulting rhythm features are stored in the rhythm variable.\n",
    "\n",
    "At last, we print the tempo and shape of the rhythm features to verify their values and dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rMXuu5avo7SZ"
   },
   "source": [
    "## 3.4 Time Series Data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nYeIwlXko7ZS"
   },
   "source": [
    "Feature extraction for time series data involves transforming raw time series data into a set of meaningful features that can be used for machine learning tasks. Here are some common feature extraction techniques for time series data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D_g4nVvEo7Vr"
   },
   "source": [
    "### I) Statistical Features: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JJzrrzYcp2gm"
   },
   "source": [
    "Statistical features capture the distributional characteristics of the time series. Examples include mean, median, variance, standard deviation, skewness, and kurtosis. These features provide information about the central tendency, variability, and shape of the time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SNEWm-1yp2WW",
    "outputId": "b53fa92e-ffaf-409c-b509-a2105206b33d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 16.3\n",
      "Median: 16.5\n",
      "Variance: 13.566666666666668\n",
      "Standard Deviation: 3.683295625749672\n",
      "Skewness: -0.23113847973527116\n",
      "Kurtosis: -0.48210372534696866\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Create a time series dataset\n",
    "data = pd.Series([10, 15, 12, 18, 20, 14, 16, 22, 19, 17])\n",
    "\n",
    "# Calculate statistical features\n",
    "mean = data.mean()\n",
    "median = data.median()\n",
    "variance = data.var()\n",
    "std_deviation = data.std()\n",
    "skewness = data.skew()\n",
    "kurtosis = data.kurtosis()\n",
    "\n",
    "# Print the calculated features\n",
    "print(\"Mean:\", mean)\n",
    "print(\"Median:\", median)\n",
    "print(\"Variance:\", variance)\n",
    "print(\"Standard Deviation:\", std_deviation)\n",
    "print(\"Skewness:\", skewness)\n",
    "print(\"Kurtosis:\", kurtosis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Aof4MNkWp2BH"
   },
   "source": [
    "By running this code, you will obtain the statistical features of the given time series. You can apply similar calculations to your own time series data to extract statistical features that provide insights into the central tendency, variability, skewness, and kurtosis of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BxwBCbgXo7cU"
   },
   "source": [
    "## II) Temporal Features: \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V7D8HoLbpzZF"
   },
   "source": [
    "Temporal features capture patterns and trends over time. Examples include autocorrelation, lagged values, moving averages, and exponential smoothing. These features help capture dependencies and relationships within the time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MKp4nZH0qW7J",
    "outputId": "98ce2993-ceb8-4bda-ea24-b72f7b76b181"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lagged Values:\n",
      "0     NaN\n",
      "1    10.0\n",
      "2    15.0\n",
      "3    12.0\n",
      "4    18.0\n",
      "5    20.0\n",
      "6    14.0\n",
      "7    16.0\n",
      "8    22.0\n",
      "9    19.0\n",
      "dtype: float64\n",
      "0     NaN\n",
      "1     NaN\n",
      "2    10.0\n",
      "3    15.0\n",
      "4    12.0\n",
      "5    18.0\n",
      "6    20.0\n",
      "7    14.0\n",
      "8    16.0\n",
      "9    22.0\n",
      "dtype: float64\n",
      "\n",
      "Moving Average:\n",
      "0          NaN\n",
      "1          NaN\n",
      "2    12.333333\n",
      "3    15.000000\n",
      "4    16.666667\n",
      "5    17.333333\n",
      "6    16.666667\n",
      "7    17.333333\n",
      "8    19.000000\n",
      "9    19.333333\n",
      "dtype: float64\n",
      "\n",
      "Moving Standard Deviation:\n",
      "0         NaN\n",
      "1         NaN\n",
      "2    2.516611\n",
      "3    3.000000\n",
      "4    4.163332\n",
      "5    3.055050\n",
      "6    3.055050\n",
      "7    4.163332\n",
      "8    3.000000\n",
      "9    2.516611\n",
      "dtype: float64\n",
      "\n",
      "Exponential Smoothing:\n",
      "0    10.000000\n",
      "1    13.333333\n",
      "2    12.571429\n",
      "3    15.466667\n",
      "4    17.806452\n",
      "5    15.873016\n",
      "6    15.937008\n",
      "7    18.980392\n",
      "8    18.990215\n",
      "9    17.994135\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Create a time series dataset\n",
    "data = pd.Series([10, 15, 12, 18, 20, 14, 16, 22, 19, 17])\n",
    "\n",
    "# Calculate temporal features\n",
    "lag_1 = data.shift(1)  # Lagged values\n",
    "lag_2 = data.shift(2)\n",
    "rolling_mean = data.rolling(window=3).mean()  # Moving average\n",
    "rolling_std = data.rolling(window=3).std()  # Moving standard deviation\n",
    "exponential_smoothing = data.ewm(alpha=0.5).mean()  # Exponential smoothing\n",
    "\n",
    "# Print the calculated features\n",
    "print(\"Lagged Values:\")\n",
    "print(lag_1)\n",
    "print(lag_2)\n",
    "print(\"\\nMoving Average:\")\n",
    "print(rolling_mean)\n",
    "print(\"\\nMoving Standard Deviation:\")\n",
    "print(rolling_std)\n",
    "print(\"\\nExponential Smoothing:\")\n",
    "print(exponential_smoothing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V6z7jjcrqdL6"
   },
   "source": [
    "By running this code, you will obtain the temporal features of the given time series. You can apply similar calculations to your own time series data to extract temporal features that capture patterns, trends, and dependencies over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JjtmZcrkpzcc"
   },
   "source": [
    "### III) Frequency Domain Features: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IpMm9fDRqf-P"
   },
   "source": [
    "Frequency domain features capture the spectral characteristics of the time series by transforming it into the frequency domain. Common techniques include Fourier transform, wavelet transform, and power spectral density estimation. These features provide information about the dominant frequencies and periodicity in the time series.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "S4kuNJ-nqtkP",
    "outputId": "124f95b3-f805-4d8d-9863-93a869d18d14"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "import numpy as np\n",
    "from scipy.fft import fft, fftfreq\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a time series dataset\n",
    "data = np.array([10, 15, 12, 18, 20, 14, 16, 22, 19, 17])\n",
    "time = np.arange(len(data))\n",
    "\n",
    "# Perform Fourier Transform\n",
    "fft_vals = fft(data)\n",
    "freqs = fftfreq(len(data))\n",
    "\n",
    "# Plot the power spectrum\n",
    "plt.plot(freqs, np.abs(fft_vals))\n",
    "plt.xlabel('Frequency')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.title('Power Spectrum')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AgGQ6CGyrUZG"
   },
   "source": [
    "By running this code, you will obtain a power spectrum plot that represents the frequency domain characteristics of the given time series. The plot shows the distribution of amplitudes across different frequency components. You can further analyze the power spectrum to extract relevant frequency domain features, such as dominant frequencies, peak amplitudes, or spectral energy distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bDUT3QWJqgIn"
   },
   "source": [
    "### IV) Waveform Shape Features: \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AVw66-OQpzf9"
   },
   "source": [
    "Waveform shape features capture the geometric properties of the time series. Examples include slope, curvature, and area under the curve. These features provide insights into the overall shape and dynamics of the time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VmHz_J2Oq-vg",
    "outputId": "4f1503e0-7551-4687-b0c3-37949df3450f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slope: [ 5.   1.   1.5  4.  -2.  -2.   4.   1.5 -2.5 -2. ]\n",
      "Curvature: [-4.   -1.75  1.5  -1.75 -3.    3.    1.75 -3.25 -1.75  0.5 ]\n",
      "Area: 149.5\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "import numpy as np\n",
    "\n",
    "# Create a time series dataset\n",
    "data = np.array([10, 15, 12, 18, 20, 14, 16, 22, 19, 17])\n",
    "\n",
    "# Calculate waveform shape features\n",
    "slope = np.gradient(data)  # Slope of the waveform\n",
    "curvature = np.gradient(np.gradient(data))  # Curvature of the waveform\n",
    "area = np.trapz(data)  # Area under the curve\n",
    "\n",
    "# Print the calculated features\n",
    "print(\"Slope:\", slope)\n",
    "print(\"Curvature:\", curvature)\n",
    "print(\"Area:\", area)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ci7uMgSqr-46"
   },
   "source": [
    "By running this code, you will obtain the waveform shape features of the given time series. You can apply similar calculations to your own time series data to extract waveform shape features that capture the slope, curvature, and overall shape characteristics of the waveform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q1-PiZpFpzjw"
   },
   "source": [
    "### V) Statistical Models: \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ahDVtekVqntl"
   },
   "source": [
    "Statistical models such as ARIMA (AutoRegressive Integrated Moving Average) or SARIMA (Seasonal ARIMA) can be used to extract features such as model parameters, residuals, and model diagnostics. These features capture the underlying patterns and relationships in the time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iSTN-q_srxgz",
    "outputId": "e5ea8a6b-0718-42c0-dcde-8edc11ea9875"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted values:\n",
      "0     -0.045295\n",
      "1     -0.092556\n",
      "2     -0.056931\n",
      "3     -0.072043\n",
      "4     -0.105011\n",
      "         ...   \n",
      "995   -0.054030\n",
      "996   -0.057263\n",
      "997   -0.041296\n",
      "998   -0.048939\n",
      "999   -0.016502\n",
      "Name: predicted_mean, Length: 1000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "# Generate a synthetic time series dataset\n",
    "np.random.seed(0)\n",
    "n = 1000\n",
    "data = pd.DataFrame({'value': np.random.randn(n)})\n",
    "\n",
    "# Extract features using ARIMA\n",
    "model = ARIMA(data['value'], order=(1, 0, 0))\n",
    "model_fit = model.fit()\n",
    "\n",
    "# Get the predicted values\n",
    "predictions = model_fit.predict(start=0, end=n-1)\n",
    "\n",
    "# Print the extracted features\n",
    "print(\"Predicted values:\")\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U3xYwUrzryOM"
   },
   "source": [
    "Keep in mind that this is a simple example using synthetic data. In real-world scenarios, you may have more complex time series data and would need to adjust the model parameters and perform additional preprocessing steps as necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9M-oDThHqnxk"
   },
   "source": [
    "### VI) Entropy-Based Features:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S_SVOiuiqn5H"
   },
   "source": [
    "Entropy-based features measure the complexity and unpredictability of the time series. Examples include approximate entropy, sample entropy, and permutation entropy. These features provide insights into the irregularity and randomness of the time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F5l4DrBort1g",
    "outputId": "7b95acd2-63da-4d6f-d2a6-70a9e2afe4d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Entropy: inf\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "import numpy as np\n",
    "from nolds import sampen\n",
    "\n",
    "# Create a time series dataset\n",
    "data = np.array([1, 2, 3, 4, 5, 4, 3, 2, 1])\n",
    "\n",
    "# Calculate sample entropy\n",
    "sample_entropy = sampen(data)\n",
    "\n",
    "# Print the calculated sample entropy\n",
    "print(\"Sample Entropy:\", sample_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uqA0u1BMruJ-"
   },
   "source": [
    "By running this code, you will obtain the sample entropy of the given time series. Sample entropy quantifies the amount of regularity or irregularity in the data. Higher values of sample entropy indicate greater complexity or randomness in the time series.\n",
    "\n",
    "Please note that nolds is just one library that provides implementations of entropy-based features. There are other libraries and methods available to calculate entropy-based features, and the choice of library may depend on the specific requirements of your analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "997wFx84qn8z"
   },
   "source": [
    "### VII) Symbolic Aggregate Approximation (SAX): \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8K18pFN7qoA5"
   },
   "source": [
    "SAX is a technique that converts the time series into a symbolic representation. It divides the time series into segments and assigns symbols to represent the segments based on their statistical properties. This enables the use of discrete and categorical features for time series analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9i0NLZICrqSw",
    "outputId": "ff862128-5e1e-42ee-ed59-a13e10330461"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAX Encoded Representation:\n",
      "[['a' 'a' 'b' 'c' 'c' 'c' 'b' 'a' 'a']]\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "import numpy as np\n",
    "from pyts.approximation import SymbolicAggregateApproximation\n",
    "\n",
    "# Create a time series dataset\n",
    "data = np.array([1, 2, 3, 4, 5, 4, 3, 2, 1])\n",
    "\n",
    "# Set the number of bins for SAX\n",
    "n_bins = 3\n",
    "\n",
    "# Perform SAX encoding\n",
    "sax = SymbolicAggregateApproximation(n_bins=n_bins)\n",
    "sax_encoded = sax.transform(data.reshape(1, -1))\n",
    "\n",
    "# Print the SAX encoded representation\n",
    "print(\"SAX Encoded Representation:\")\n",
    "print(sax_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eSkdjpOcrqd7"
   },
   "source": [
    "By running this code, you will obtain the SAX encoded representation of the given time series. SAX represents the time series using a set of symbols, each symbol corresponding to a specific range of values. The length of the SAX representation is typically shorter than the original time series, providing a more compact representation for further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x_9GBP8RqoEb"
   },
   "source": [
    "### VIII) Deep Learning-based Features: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UDitf0Parj_e"
   },
   "source": [
    "Deep learning techniques such as recurrent neural networks (RNNs) and convolutional neural networks (CNNs) can automatically learn meaningful representations from raw time series data. Features can be extracted from intermediate layers or learned directly from the input time series using techniques like transfer learning or autoencoders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6AzMIfecrkLO"
   },
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import numpy as np\n",
    "from keras.applications import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "\n",
    "# Load the pre-trained CNN model\n",
    "model = VGG16(weights='imagenet', include_top=False)\n",
    "\n",
    "# Load and preprocess the image\n",
    "img_path = 'image.jpg'  # Path to your image\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "# Extract deep learning-based features\n",
    "features = model.predict(x)\n",
    "\n",
    "# Flatten the features\n",
    "features = features.flatten()\n",
    "\n",
    "# Print the extracted features\n",
    "print(\"Deep Learning-based Features:\")\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "erHuC2z2rkVG"
   },
   "source": [
    "Note that this example demonstrates feature extraction from an image using a pre-trained CNN model. The process may vary depending on the type of data (e.g., images, text, audio) and the specific deep learning model being used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G0Elp-CNv6XU"
   },
   "source": [
    "These are just a few examples of feature extraction techniques for time series data. The choice of techniques depends on the specific characteristics and objectives of the time series data analysis task. It's important to explore and experiment with different feature extraction methods to identify the most relevant and informative features for the specific problem at hand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jK7hXsN-WKrk"
   },
   "source": [
    "## 4. Feature Selection Methods:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UDRme-eEan5N"
   },
   "source": [
    "Feature selection is an important step in machine learning and data analysis that aims to identify and select the most relevant features from a given set of features. The goal of feature selection is to improve model performance, reduce overfitting, enhance interpretability, and reduce computational complexity.\n",
    "\n",
    "Feature selection not only improves model performance but also offers benefits such as reducing training time, enhancing model interpretability, and handling high-dimensional data. It helps to focus on the most informative features, eliminating noise and irrelevant information, leading to more efficient and effective machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q338uyjKbAYi"
   },
   "source": [
    "### 4.1 Filter Methods:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H7yiVKx3an-_"
   },
   "source": [
    "Filter methods evaluate the relevance of features based on their statistical properties, such as correlation, variance, or mutual information. These methods rank or score features independently of the machine learning algorithm used. Common filter methods include correlation coefficient, chi-square test, information gain, and variance threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y9r63_nZbGXH",
    "outputId": "9db1f3d2-15a6-4a7c-92f2-7def60e9f25f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mutual information scores: [0.01072823 0.         0.05089959 0.0034255  0.12904149 0.01035763\n",
      " 0.00115023 0.06558639 0.09090014 0.        ]\n",
      "Selected features using mutual information gain: [4 8 7 2 0]\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "import numpy as np\n",
    "\n",
    "# Create a random dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=0, random_state=42)\n",
    "\n",
    "# Apply mutual information gain to select features\n",
    "mi_selector = SelectKBest(mutual_info_classif, k=5)\n",
    "mi_selector.fit(X, y)\n",
    "\n",
    "# Get the scores for each feature\n",
    "mi_scores = mi_selector.scores_\n",
    "\n",
    "# Print the scores\n",
    "print(\"Mutual information scores:\", mi_scores)\n",
    "\n",
    "# Print the selected features based on scores\n",
    "selected_mi_indices = np.argsort(mi_scores)[::-1][:5]\n",
    "print(\"Selected features using mutual information gain:\", selected_mi_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v5oraYmdeOMM"
   },
   "source": [
    "### 4.2 Wrapper Methods:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gCqhqzZeeSY2"
   },
   "source": [
    "Wrapper methods evaluate the performance of a machine learning algorithm by considering different subsets of features. They use a specific machine learning algorithm as a black box to assess the quality of the feature subset. Examples of wrapper methods include forward selection, backward elimination, and recursive feature elimination (RFE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q5_mEzQlblCU",
    "outputId": "2be056f3-2554-4849-9402-85fda60731b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features:\n",
      "Feature 3\n",
      "Feature 4\n",
      "Feature 6\n",
      "Feature 7\n",
      "Feature 8\n",
      "Feature 11\n",
      "Feature 13\n",
      "Feature 14\n",
      "Feature 15\n",
      "Feature 16\n",
      "Feature 17\n",
      "Feature 19\n",
      "Feature 20\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create a random dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=10, random_state=42)\n",
    "\n",
    "# Create a base classifier\n",
    "clf = LogisticRegression()\n",
    "\n",
    "# Create a recursive feature elimination object with cross-validation\n",
    "rfecv = RFECV(estimator=clf, cv=5)\n",
    "\n",
    "# Fit the recursive feature elimination model\n",
    "rfecv.fit(X, y)\n",
    "\n",
    "# Get the selected feature indices\n",
    "selected_indices = rfecv.support_\n",
    "\n",
    "# Get the selected feature names\n",
    "selected_features = [f\"Feature {i}\" for i, selected in enumerate(selected_indices, start=1) if selected]\n",
    "\n",
    "# Print the selected feature names\n",
    "print(\"Selected features:\")\n",
    "for feature in selected_features:\n",
    "    print(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mgQqnc8yeqcA"
   },
   "source": [
    "Note that you may need to adjust the code based on the specific dataset and classifier you are using. Additionally, you can modify the parameters of RFECV, such as scoring metrics or step size, to suit your requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sDOMKMhpetqY"
   },
   "source": [
    "### 4.3 Embedded Methods:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ITOFM959etuW"
   },
   "source": [
    "Embedded methods perform feature selection as an integral part of the machine learning algorithm. They select features during the model training process, taking into account their importance in relation to the model's performance. Embedded methods include techniques such as L1 regularization (Lasso), decision tree-based feature importance, and gradient boosting feature importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jL2AdUdpejr2",
    "outputId": "78c76b95-c19b-4ea1-aa13-57a2dab498ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features:\n",
      "Feature 1\n",
      "Feature 2\n",
      "Feature 4\n",
      "Feature 5\n",
      "Feature 6\n",
      "Feature 7\n",
      "Feature 9\n",
      "Feature 10\n",
      "Feature 11\n",
      "Feature 12\n",
      "Feature 13\n",
      "Feature 14\n",
      "Feature 15\n",
      "Feature 16\n",
      "Feature 17\n",
      "Feature 18\n",
      "Feature 19\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create a random dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=10, random_state=42)\n",
    "\n",
    "# Create a logistic regression model with L1 regularization\n",
    "model = LogisticRegression(penalty='l1', solver='liblinear')\n",
    "\n",
    "# Fit the model to the data\n",
    "model.fit(X, y)\n",
    "\n",
    "# Get the coefficients of the features\n",
    "coefficients = model.coef_\n",
    "\n",
    "# Get the selected feature indices\n",
    "selected_indices = [i for i, coef in enumerate(coefficients[0]) if coef != 0]\n",
    "\n",
    "# Get the selected feature names\n",
    "selected_features = [f\"Feature {i}\" for i in selected_indices]\n",
    "\n",
    "# Print the selected feature names\n",
    "print(\"Selected features:\")\n",
    "for feature in selected_features:\n",
    "    print(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qwmisaN8e_ib"
   },
   "source": [
    "Each feature selection method has its strengths and limitations, and the choice of method depends on the specific problem and data characteristics. It is often recommended to try different feature selection techniques and compare their results to find the most suitable one for a particular task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lK_PjdX_fA4M"
   },
   "source": [
    "## 5. Feature Construction Techniques:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KEy2v6mifA7r"
   },
   "source": [
    "Feature construction techniques involve creating new features from existing ones to enhance the predictive power of a machine learning model. Here's a brief overview of common feature construction techniques:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3X_G3yGyfBCL"
   },
   "source": [
    "### 5.1 Polynomial Features: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eu_rJcgYfvOQ"
   },
   "source": [
    "This technique involves creating new features by taking the polynomial combinations of the original features. For example, given a feature x, polynomial features can include x^2, x^3, etc. This allows the model to capture non-linear relationships between features and the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NSMa-23If8_I",
    "outputId": "5accce7f-4693-4378-b99a-d3b7b22b9717"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original features:\n",
      "[[1 2]\n",
      " [3 4]\n",
      " [5 6]]\n",
      "Polynomial features:\n",
      "[[ 1.  1.  2.  1.  2.  4.]\n",
      " [ 1.  3.  4.  9. 12. 16.]\n",
      " [ 1.  5.  6. 25. 30. 36.]]\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import numpy as np\n",
    "\n",
    "# Create a sample dataset\n",
    "X = np.array([[1, 2], [3, 4], [5, 6]])\n",
    "\n",
    "# Create polynomial features with degree 2\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_poly = poly.fit_transform(X)\n",
    "\n",
    "# Print the original features\n",
    "print(\"Original features:\")\n",
    "print(X)\n",
    "\n",
    "# Print the polynomial features\n",
    "print(\"Polynomial features:\")\n",
    "print(X_poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FJaI527If9Lh"
   },
   "source": [
    "The polynomial features include the original features as well as the combinations up to degree 2. In this case, the polynomial features include the constant term (1), the original features ([1, 2], [3, 4], [5, 6]), and the combinations of the original features (11, 12, 22, 33, 34, 44, 55, 56, 6*6).\n",
    "\n",
    "You can adjust the degree parameter to create polynomial features of higher degrees if desired."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XHGEDKGEfvR3"
   },
   "source": [
    "### 5.2 Interactions Term:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yzl7J6sPfvVH"
   },
   "source": [
    "Interaction features are created by combining two or more existing features using mathematical operations like multiplication, division, or addition. These features capture interactions between different variables and can provide additional information to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZA6eBoq-gNQh",
    "outputId": "08ba4693-30e5-4a37-f530-89d2b54f49d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original features:\n",
      "[[1 2]\n",
      " [3 4]\n",
      " [5 6]]\n",
      "Interaction terms:\n",
      "[[ 1.  2.  2.]\n",
      " [ 3.  4. 12.]\n",
      " [ 5.  6. 30.]]\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import numpy as np\n",
    "\n",
    "# Create a sample dataset\n",
    "X = np.array([[1, 2], [3, 4], [5, 6]])\n",
    "\n",
    "# Create interaction terms\n",
    "interaction = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
    "X_interaction = interaction.fit_transform(X)\n",
    "\n",
    "# Print the original features\n",
    "print(\"Original features:\")\n",
    "print(X)\n",
    "\n",
    "# Print the interaction terms\n",
    "print(\"Interaction terms:\")\n",
    "print(X_interaction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kTMLpes_fvY6"
   },
   "source": [
    "The interaction terms include the original features as well as the products of the features. In this case, the interaction terms are calculated as follows:\n",
    "\n",
    "The first row: 1 * 2, 1 * 2 (the same feature), 2 * 2\n",
    "\n",
    "The second row: 3 * 4, 3 * 4 (the same feature), 4 * 4\n",
    "\n",
    "The third row: 5 * 6, 5 * 6 (the same feature), 6 * 6\n",
    "\n",
    "This way, you obtain interaction terms that capture the combined effects of the original features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L_eywvolfvcF"
   },
   "source": [
    "### 5.3 Domain-Specific Features: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rX6V8hbLfvfF"
   },
   "source": [
    "Domain knowledge plays a crucial role in feature construction. Understanding the problem domain allows for the creation of relevant and meaningful features. For example, in natural language processing, features like word counts, sentence length, or part-of-speech tags can be constructed to capture linguistic information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vGdh-iQogKmo",
    "outputId": "cefad998-eec9-452f-f277-aaabbda7ab50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   text category  word_count  avg_word_length  stopword_count  \\\n",
      "0     I love this movie    movie           4             3.50               2   \n",
      "1  This book is amazing     book           4             4.25               2   \n",
      "2  The weather is great  weather           4             4.25               2   \n",
      "\n",
      "                                       tfidf_feature  \n",
      "0  [0.0, 0.0, 0.0, 0.0, 0.6227660078332259, 0.622...  \n",
      "1  [0.5628290964997665, 0.5628290964997665, 0.0, ...  \n",
      "2  [0.0, 0.0, 0.5286346066596935, 0.4020402441612...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Example dataset\n",
    "data = pd.DataFrame({'text': ['I love this movie', 'This book is amazing', 'The weather is great'],\n",
    "                     'category': ['movie', 'book', 'weather']})\n",
    "\n",
    "# Domain-specific feature: Word Count\n",
    "data['word_count'] = data['text'].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "# Domain-specific feature: Average Word Length\n",
    "data['avg_word_length'] = data['text'].apply(lambda x: np.mean([len(word) for word in str(x).split()]))\n",
    "\n",
    "# Domain-specific feature: Stopword Count\n",
    "stop_words = set(stopwords.words('english'))\n",
    "data['stopword_count'] = data['text'].apply(lambda x: len([word for word in str(x).split() if word.lower() in stop_words]))\n",
    "\n",
    "# Domain-specific feature: Term Frequency-Inverse Document Frequency (TF-IDF)\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf_features = tfidf.fit_transform(data['text'])\n",
    "data['tfidf_feature'] = [tfidf_features[i].toarray().tolist()[0] for i in range(tfidf_features.shape[0])]\n",
    "\n",
    "# Print the modified dataset\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-a9D34N_iR6b"
   },
   "source": [
    "In this code snippet, we start by importing the necessary libraries, including NLTK for stopword removal, and scikit-learn's TfidfVectorizer for TF-IDF feature extraction.\n",
    "\n",
    "We then create an example dataset consisting of text samples and their corresponding categories.\n",
    "\n",
    "Next, we create domain-specific features:\n",
    "\n",
    "1. Word Count: We count the number of words in each text sample using the split() function and len().\n",
    "\n",
    "2. Average Word Length: We calculate the average length of words in each text sample by iterating over the words and calculating their lengths.\n",
    "\n",
    "3. Stopword Count: We count the number of stopwords in each text sample by checking if each word is in the list of stopwords.\n",
    "\n",
    "4. TF-IDF Feature: We apply TF-IDF feature extraction using the TfidfVectorizer and store the resulting features in a separate column. Each TF-IDF feature is represented as a list of TF-IDF values for each word in the corresponding text sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jOCbBhJmgLXq"
   },
   "source": [
    "The output will display the original dataset with the added domain-specific features, such as word count, average word length, stopword count, and TF-IDF features for each text sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ENHXPnlgLhF"
   },
   "source": [
    "### 5.4 Revisiting Feature Scaling:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DX1sX6wbgUB9"
   },
   "source": [
    "Transforming features through scaling or normalization can sometimes improve the performance of a model. Techniques like min-max scaling or z-score normalization can ensure that features are on similar scales and have comparable importance during model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6mz8Y-ingTXP",
    "outputId": "a857d78e-caed-4005-adfa-ebd736b5da9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original features:\n",
      "[[1 2]\n",
      " [3 4]\n",
      " [5 6]]\n",
      "Scaled features:\n",
      "[[-1.22474487 -1.22474487]\n",
      " [ 0.          0.        ]\n",
      " [ 1.22474487  1.22474487]]\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Create a sample dataset\n",
    "X = np.array([[1, 2], [3, 4], [5, 6]])\n",
    "\n",
    "# Create a StandardScaler object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Perform feature scaling\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Print the original features\n",
    "print(\"Original features:\")\n",
    "print(X)\n",
    "\n",
    "# Print the scaled features\n",
    "print(\"Scaled features:\")\n",
    "print(X_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8wFUSOufijmO"
   },
   "source": [
    "The scaled features have zero mean and unit variance, which means they are centered around zero and have a standard deviation of 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ASI3eBetinVh"
   },
   "source": [
    "It's important to note that feature construction should be guided by domain knowledge, intuition, and an understanding of the problem at hand. Experimentation and iterative improvement of features can lead to better model performance. Additionally, feature construction should be performed in conjunction with appropriate feature selection techniques to avoid overfitting and improve model interpretability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-vEicFbiir2q"
   },
   "source": [
    "## 6. Feature Encoding Methods:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P-wMG22yi_4f"
   },
   "source": [
    "Feature encoding methods are used to convert categorical or text features into numerical representations that can be effectively used by machine learning algorithms. Here's a short note on some commonly used feature encoding methods:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MuW8CEM6i_9j"
   },
   "source": [
    "### 6.1 One-Hot Encoding:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eIcK3Z0MjACC"
   },
   "source": [
    "This method is used for nominal categorical features. It creates binary columns for each category, where each column indicates the presence or absence of a category. This approach increases the dimensionality of the data but ensures that each category is represented independently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mb2xfkWijkCf",
    "outputId": "01f2f696-646d-4da6-bc09-c082a3688269"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Color  Color_Blue  Color_Green  Color_Red  Color_Yellow\n",
      "0     Red         0.0          0.0        1.0           0.0\n",
      "1    Blue         1.0          0.0        0.0           0.0\n",
      "2   Green         0.0          1.0        0.0           0.0\n",
      "3     Red         0.0          0.0        1.0           0.0\n",
      "4  Yellow         0.0          0.0        0.0           1.0\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Create a sample dataset\n",
    "data = pd.DataFrame({'Color': ['Red', 'Blue', 'Green', 'Red', 'Yellow']})\n",
    "\n",
    "# Create an instance of OneHotEncoder\n",
    "encoder = OneHotEncoder()\n",
    "\n",
    "# Apply one-hot encoding\n",
    "encoded_data = encoder.fit_transform(data[['Color']]).toarray()\n",
    "\n",
    "# Create a new dataframe with the encoded features\n",
    "encoded_df = pd.DataFrame(encoded_data, columns=encoder.get_feature_names_out(['Color']))\n",
    "\n",
    "# Concatenate the original dataframe and the encoded dataframe\n",
    "final_data = pd.concat([data, encoded_df], axis=1)\n",
    "\n",
    "# Print the final dataset\n",
    "print(final_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9HfyymdsjkRJ"
   },
   "source": [
    "The output will display the original dataset followed by the one-hot encoded features. Each category from the original 'Color' feature is represented as a binary column, where a value of 1 indicates the presence of the category and 0 indicates its absence.\n",
    "\n",
    "You can apply one-hot encoding to your own dataset by creating an instance of the OneHotEncoder class and using the fit_transform method on your categorical features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "__cz1FVWjAGJ"
   },
   "source": [
    "### 6.2 Label Encoding:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TINtWRQQjboB"
   },
   "source": [
    "Label encoding is used for ordinal categorical features. It assigns a unique numerical label to each category, preserving the order of the categories. However, this encoding may introduce unintended ordinal relationships between categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T8CxFCCskJTL",
    "outputId": "89aeb18a-df73-485d-a36d-dcf5f5c3ca27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Color  Encoded_Color\n",
      "0     Red              2\n",
      "1    Blue              0\n",
      "2   Green              1\n",
      "3     Red              2\n",
      "4  Yellow              3\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Create a sample dataset\n",
    "data = pd.DataFrame({'Color': ['Red', 'Blue', 'Green', 'Red', 'Yellow']})\n",
    "\n",
    "# Create an instance of LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# Apply label encoding\n",
    "encoded_data = encoder.fit_transform(data['Color'])\n",
    "\n",
    "# Add the encoded feature to the dataset\n",
    "data['Encoded_Color'] = encoded_data\n",
    "\n",
    "# Print the final dataset\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hi4apIPekJbP"
   },
   "source": [
    "In the encoded feature, each category from the original 'Color' feature is represented by a numerical label assigned by the LabelEncoder. The labels correspond to the order in which the categories are encountered in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Hr-CXE5jbsK"
   },
   "source": [
    "### 6.3 Target Encoding:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2MqH0kcJjbvq"
   },
   "source": [
    "Target encoding replaces each category with the average value of the target variable for that category. It can capture the relationship between a category and the target variable, but it may introduce target leakage if not properly handled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FuxAyELGka-K",
    "outputId": "0e29bb60-6d31-4836-b360-6e8ee89cdeed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Color  Target  Encoded_Color\n",
      "0     Red      10      15.148894\n",
      "1    Blue      20      16.520434\n",
      "2   Green      15      15.869892\n",
      "3     Red      10      15.148894\n",
      "4  Yellow      25      17.170976\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "import pandas as pd\n",
    "import category_encoders as ce\n",
    "\n",
    "# Create a sample dataset\n",
    "data = pd.DataFrame({'Color': ['Red', 'Blue', 'Green', 'Red', 'Yellow'],\n",
    "                     'Target': [10, 20, 15, 10, 25]})\n",
    "\n",
    "# Create an instance of TargetEncoder\n",
    "encoder = ce.TargetEncoder(cols=['Color'])\n",
    "\n",
    "# Apply target encoding\n",
    "encoded_data = encoder.fit_transform(data['Color'], data['Target'])\n",
    "\n",
    "# Add the encoded feature to the dataset\n",
    "data['Encoded_Color'] = encoded_data\n",
    "\n",
    "# Print the final dataset\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jc8ChJdskbK_"
   },
   "source": [
    "In the encoded feature, each category from the original 'Color' feature is replaced with the mean target value for that category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z_gd7kj3jAKL"
   },
   "source": [
    "### 6.4 Frequency Encoding:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LIyr0wKSjgqT"
   },
   "source": [
    "Frequency encoding is a technique used in feature engineering to encode categorical variables by replacing each category with its frequency or occurrence in the dataset. It is a simple yet effective way to capture the distribution and importance of different categories in a categorical feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bem32QtalVbs",
    "outputId": "fae82e62-54fd-4a7a-cb1b-8a8817e195d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Color  Encoded_Color\n",
      "0     Red              2\n",
      "1    Blue              1\n",
      "2   Green              1\n",
      "3     Red              2\n",
      "4  Yellow              1\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Create a sample dataset\n",
    "data = pd.DataFrame({'Color': ['Red', 'Blue', 'Green', 'Red', 'Yellow']})\n",
    "\n",
    "# Calculate the frequency of each category\n",
    "category_counts = data['Color'].value_counts()\n",
    "\n",
    "# Apply frequency encoding\n",
    "encoded_data = data['Color'].map(category_counts)\n",
    "\n",
    "# Add the encoded feature to the dataset\n",
    "data['Encoded_Color'] = encoded_data\n",
    "\n",
    "# Print the final dataset\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UcOcUg8qlVjX"
   },
   "source": [
    "In the encoded feature, each category from the original 'Color' feature is replaced with its frequency or occurrence in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nOq536DQlV80"
   },
   "source": [
    "These feature encoding methods play a crucial role in preparing categorical or text data for machine learning models. The choice of encoding method depends on the nature of the data, the specific problem, and the requirements of the machine learning algorithm being used. It is important to carefully consider the characteristics of the data and the potential impact of encoding methods on the model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PgHfQY7SlouQ"
   },
   "source": [
    "## 7. Handling Imbalanced Data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4MWNU-3NlozH"
   },
   "source": [
    "Handling imbalanced data is an important aspect of machine learning, especially when the distribution of the target variable is skewed, and one class is significantly more prevalent than the others. Imbalanced data can lead to biased models and poor performance, as the classifier tends to favor the majority class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J5ilk4_llo3I"
   },
   "source": [
    "### 7.1 Undersampling:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C_Qvh7hfmCJB"
   },
   "source": [
    "Undersampling is a resampling technique used to address imbalanced data by reducing the number of samples in the majority class to balance it with the minority class. This technique aims to create a more balanced distribution of the target variable, thereby avoiding bias towards the majority class during model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6YcfPplQmshM",
    "outputId": "656e90e4-99f2-48ab-a734-f70e51a98002"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Class Distribution:\n",
      "0    896\n",
      "1    104\n",
      "Name: target, dtype: int64\n",
      "\n",
      "Undersampled Class Distribution:\n",
      "0    104\n",
      "1    104\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Create an unbalanced dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, weights=[0.9, 0.1], random_state=42)\n",
    "\n",
    "# Convert the data to a DataFrame\n",
    "data = pd.DataFrame(X, columns=[f\"feature_{i}\" for i in range(10)])\n",
    "data['target'] = y\n",
    "\n",
    "# Count the class distribution\n",
    "class_counts = data['target'].value_counts()\n",
    "print(\"Original Class Distribution:\")\n",
    "print(class_counts)\n",
    "\n",
    "# Apply undersampling\n",
    "undersampler = RandomUnderSampler(random_state=42)\n",
    "X_undersampled, y_undersampled = undersampler.fit_resample(X, y)\n",
    "\n",
    "# Convert the undersampled data to a DataFrame\n",
    "undersampled_data = pd.DataFrame(X_undersampled, columns=[f\"feature_{i}\" for i in range(10)])\n",
    "undersampled_data['target'] = y_undersampled\n",
    "\n",
    "# Count the class distribution after undersampling\n",
    "undersampled_class_counts = undersampled_data['target'].value_counts()\n",
    "print(\"\\nUndersampled Class Distribution:\")\n",
    "print(undersampled_class_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jVS6w2BgmsrD"
   },
   "source": [
    "By running this code, you will create an unbalanced dataset, apply undersampling to balance the classes, and observe the class distributions before and after undersampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XqnOmKMPmCMZ"
   },
   "source": [
    "### 7.2 Oversampling:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZOkQDKlTmCQI"
   },
   "source": [
    "Oversampling is a resampling technique used to address imbalanced data by increasing the number of samples in the minority class. In imbalanced datasets, the minority class is underrepresented, leading to biased models that may have difficulty correctly predicting the minority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VYJvhXqgoCbW",
    "outputId": "2905ffad-aac4-4af2-cd81-22856e890ee6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Class Distribution:\n",
      "0    896\n",
      "1    104\n",
      "Name: target, dtype: int64\n",
      "\n",
      "Oversampled Class Distribution:\n",
      "0    896\n",
      "1    896\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Create an imbalanced dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, weights=[0.9, 0.1], random_state=42)\n",
    "\n",
    "# Convert the data to a DataFrame\n",
    "data = pd.DataFrame(X, columns=[f\"feature_{i}\" for i in range(10)])\n",
    "data['target'] = y\n",
    "\n",
    "# Count the class distribution\n",
    "class_counts = data['target'].value_counts()\n",
    "print(\"Original Class Distribution:\")\n",
    "print(class_counts)\n",
    "\n",
    "# Apply oversampling\n",
    "oversampler = RandomOverSampler(random_state=42)\n",
    "X_oversampled, y_oversampled = oversampler.fit_resample(X, y)\n",
    "\n",
    "# Convert the oversampled data to a DataFrame\n",
    "oversampled_data = pd.DataFrame(X_oversampled, columns=[f\"feature_{i}\" for i in range(10)])\n",
    "oversampled_data['target'] = y_oversampled\n",
    "\n",
    "# Count the class distribution after oversampling\n",
    "oversampled_class_counts = oversampled_data['target'].value_counts()\n",
    "print(\"\\nOversampled Class Distribution:\")\n",
    "print(oversampled_class_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HwFDjnu6mCTZ"
   },
   "source": [
    "### 7.3 Synthetic Minority Over-sampling Technique (SMOTE):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "odxDiUDKlo82"
   },
   "source": [
    "SMOTE generates synthetic samples by interpolating between existing minority class samples. It selects a minority class sample, finds its k nearest neighbors, and creates synthetic samples along the line segments connecting the sample and its neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oFzu_Do1oaco",
    "outputId": "7861d140-75aa-4d67-e8af-8e576fe091d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Class Distribution:\n",
      "0    896\n",
      "1    104\n",
      "dtype: int64\n",
      "\n",
      "Class Distribution after SMOTE:\n",
      "0    896\n",
      "1    896\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Create an imbalanced dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, weights=[0.9, 0.1], random_state=42)\n",
    "\n",
    "# Apply SMOTE oversampling\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Print the class distribution before and after SMOTE\n",
    "print(\"Original Class Distribution:\")\n",
    "print(pd.Series(y).value_counts())\n",
    "\n",
    "print(\"\\nClass Distribution after SMOTE:\")\n",
    "print(pd.Series(y_resampled).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-jUsV6FjoalQ"
   },
   "source": [
    "By running this code, you will create an imbalanced dataset, apply SMOTE oversampling, and observe the class distributions before and after applying SMOTE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nYlbmLq0vrye"
   },
   "source": [
    "It's important to carefully evaluate the impact of each strategy on the model's performance and consider the specific characteristics of the dataset. There is no one-size-fits-all solution, and the choice of approach depends on the specific problem and the available data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tuppYP-MoucQ"
   },
   "source": [
    "## 8. Feature Engineering for Time Series Data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QdsKrmH-vF8H"
   },
   "source": [
    "Feature engineering for time series data involves creating meaningful and informative features from raw time series data. Here are some common techniques for feature engineering in time series data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ajtmXZHVoufp"
   },
   "source": [
    "### 8.1 Lagged Features:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AIvqQz-xvGt5"
   },
   "source": [
    "Lag features involve using previous observations as features. They can capture temporal patterns and dependencies in the data. For example, you can create lag features by including the values of the time series at previous time steps, such as lag-1, lag-2, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j2CxfxqWveTe",
    "outputId": "9414cc85-da03-4293-bb0e-7ea1f9ab4c0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lagged Features:\n",
      "   Lag_1  Lag_2\n",
      "2   20.0   10.0\n",
      "3   30.0   20.0\n",
      "4   40.0   30.0\n",
      "5   50.0   40.0\n",
      "6   60.0   50.0\n",
      "7   70.0   60.0\n",
      "8   80.0   70.0\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create a sample time series data\n",
    "data = pd.Series([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
    "\n",
    "# Define the number of lag observations\n",
    "num_lags = 2\n",
    "\n",
    "# Create lagged features\n",
    "lagged_features = pd.DataFrame()\n",
    "for i in range(1, num_lags + 1):\n",
    "    lagged_features[f'Lag_{i}'] = data.shift(i)\n",
    "\n",
    "# Remove rows with missing values\n",
    "lagged_features = lagged_features.dropna()\n",
    "\n",
    "# Print the lagged features\n",
    "print(\"Lagged Features:\")\n",
    "print(lagged_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6YfUEGz5ykkX"
   },
   "source": [
    "Note that this code snippet demonstrates creating lagged features for a univariate time series. If you have a multivariate time series, you can extend the code to include lagged features for each variable by shifting the corresponding columns. Additionally, you can experiment with different numbers of lag observations to capture different temporal dependencies in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Wv-QFX4oujQ"
   },
   "source": [
    "### 8.2 Rolling and Expanding Window Statistics:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qhogyyj5vHVa"
   },
   "source": [
    "Rolling window statistics involve calculating summary statistics over a fixed window of time. Common examples include the mean, median, standard deviation, minimum, maximum, and percentiles. These statistics provide information about the trends, variability, and distribution of the time series within a specific window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BH090c5CvmLl",
    "outputId": "d09e38f2-1a76-49cf-d71a-14f78beefa0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rolling Window Statistics:\n",
      "Rolling Mean:\n",
      "0     NaN\n",
      "1     NaN\n",
      "2    20.0\n",
      "3    30.0\n",
      "4    40.0\n",
      "5    50.0\n",
      "6    60.0\n",
      "7    70.0\n",
      "8    80.0\n",
      "dtype: float64\n",
      "Rolling Standard Deviation:\n",
      "0     NaN\n",
      "1     NaN\n",
      "2    10.0\n",
      "3    10.0\n",
      "4    10.0\n",
      "5    10.0\n",
      "6    10.0\n",
      "7    10.0\n",
      "8    10.0\n",
      "dtype: float64\n",
      "\n",
      "Expanding Window Statistics:\n",
      "Expanding Mean:\n",
      "0    10.0\n",
      "1    15.0\n",
      "2    20.0\n",
      "3    25.0\n",
      "4    30.0\n",
      "5    35.0\n",
      "6    40.0\n",
      "7    45.0\n",
      "8    50.0\n",
      "dtype: float64\n",
      "Expanding Standard Deviation:\n",
      "0          NaN\n",
      "1     7.071068\n",
      "2    10.000000\n",
      "3    12.909944\n",
      "4    15.811388\n",
      "5    18.708287\n",
      "6    21.602469\n",
      "7    24.494897\n",
      "8    27.386128\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create a sample time series data\n",
    "data = pd.Series([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
    "\n",
    "# Define the window size\n",
    "window_size = 3\n",
    "\n",
    "# Calculate rolling window statistics\n",
    "rolling_mean = data.rolling(window_size).mean()\n",
    "rolling_std = data.rolling(window_size).std()\n",
    "\n",
    "# Calculate expanding window statistics\n",
    "expanding_mean = data.expanding().mean()\n",
    "expanding_std = data.expanding().std()\n",
    "\n",
    "# Print the rolling and expanding window statistics\n",
    "print(\"Rolling Window Statistics:\")\n",
    "print(\"Rolling Mean:\")\n",
    "print(rolling_mean)\n",
    "print(\"Rolling Standard Deviation:\")\n",
    "print(rolling_std)\n",
    "\n",
    "print(\"\\nExpanding Window Statistics:\")\n",
    "print(\"Expanding Mean:\")\n",
    "print(expanding_mean)\n",
    "print(\"Expanding Standard Deviation:\")\n",
    "print(expanding_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xbv2pVqDzXIt"
   },
   "source": [
    "Note that you can experiment with different window sizes to capture different temporal patterns and dependencies in the data. Additionally, pandas provides various other rolling and expanding window functions such as min(), max(), sum(), etc., that can be used to calculate different summary statistics over the windows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "doKE7ZuYvBkD"
   },
   "source": [
    "### 8.3 Time-based Features:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NUVPsX-TviTY"
   },
   "source": [
    "Time-based features can capture patterns related to specific time components. For example, you can extract features such as the hour of the day, day of the week, month, season, or year from the timestamp of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DUwPCyegvlYU",
    "outputId": "631b20f0-6177-4498-d47e-cff1d1be337d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            timestamp  hour  day  month  year  weekday\n",
      "0 2023-01-01 09:00:00     9    1      1  2023        6\n",
      "1 2023-01-01 12:30:00    12    1      1  2023        6\n",
      "2 2023-01-02 14:45:00    14    2      1  2023        0\n",
      "3 2023-01-02 18:20:00    18    2      1  2023        0\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Create a sample DataFrame with a timestamp column\n",
    "data = pd.DataFrame({\n",
    "    'timestamp': ['2023-01-01 09:00:00', '2023-01-01 12:30:00', '2023-01-02 14:45:00', '2023-01-02 18:20:00']\n",
    "})\n",
    "\n",
    "# Convert the timestamp column to datetime type\n",
    "data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
    "\n",
    "# Extract time-based features\n",
    "data['hour'] = data['timestamp'].dt.hour\n",
    "data['day'] = data['timestamp'].dt.day\n",
    "data['month'] = data['timestamp'].dt.month\n",
    "data['year'] = data['timestamp'].dt.year\n",
    "data['weekday'] = data['timestamp'].dt.weekday\n",
    "\n",
    "# Print the extracted time-based features\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IVTOqVV4zZVZ"
   },
   "source": [
    "You can use these time-based features as input for further analysis or modeling tasks. Depending on the specific requirements of your problem, you can extract additional time-based features such as quarter, season, time of day (morning, afternoon, evening), or time since a specific event."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dqjWh8Fpznfu"
   },
   "source": [
    "These techniques are not exhaustive, and the choice of features depends on the specific characteristics of the time series and the problem at hand. It is often beneficial to experiment with different feature engineering techniques and domain knowledge to create a set of informative features for modeling and analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uvc2JtyFznun"
   },
   "source": [
    "## 9. Advanced Feature Engineering Techniques:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mvdt5xKtznzN"
   },
   "source": [
    "Advanced feature engineering techniques go beyond basic transformations and extraction methods to create more informative and powerful features. These techniques often involve domain knowledge, creative problem-solving, and a deep understanding of the data. Here are some advanced feature engineering techniques:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XgpiqkCdzn4L"
   },
   "source": [
    "### 9.1 Feature Embeddings:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G45o8BBizyYm"
   },
   "source": [
    " Embeddings are low-dimensional vector representations of categorical variables. They are generated using techniques such as Word2Vec or GloVe, which learn dense numerical representations that capture the semantic meaning of categorical variables. Embeddings are widely used in natural language processing (NLP) tasks but can also be applied to other categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CQWYy7Xn0hl9",
    "outputId": "e98f3cbc-6099-4fed-9942-726258bdff7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8.1681199e-03 -4.4430327e-03  8.9854337e-03  8.2536647e-03\n",
      " -4.4352221e-03  3.0310510e-04  4.2744912e-03 -3.9263200e-03\n",
      " -5.5599655e-03 -6.5123225e-03 -6.7073823e-04 -2.9592158e-04\n",
      "  4.4630850e-03 -2.4740540e-03 -1.7260908e-04  2.4618758e-03\n",
      "  4.8675989e-03 -3.0808449e-05 -6.3394094e-03 -9.2608072e-03\n",
      "  2.6657581e-05  6.6618943e-03  1.4660227e-03 -8.9665223e-03\n",
      " -7.9386048e-03  6.5519023e-03 -3.7856805e-03  6.2549924e-03\n",
      " -6.6810320e-03  8.4796622e-03 -6.5163244e-03  3.2880199e-03\n",
      " -1.0569858e-03 -6.7875278e-03 -3.2875966e-03 -1.1614120e-03\n",
      " -5.4709399e-03 -1.2113475e-03 -7.5633135e-03  2.6466595e-03\n",
      "  9.0701487e-03 -2.3772502e-03 -9.7651005e-04  3.5135616e-03\n",
      "  8.6650876e-03 -5.9218528e-03 -6.8875779e-03 -2.9329848e-03\n",
      "  9.1476962e-03  8.6626766e-04 -8.6784009e-03 -1.4469790e-03\n",
      "  9.4794659e-03 -7.5494875e-03 -5.3580985e-03  9.3165627e-03\n",
      " -8.9737261e-03  3.8259076e-03  6.6544057e-04  6.6607012e-03\n",
      "  8.3127534e-03 -2.8507852e-03 -3.9923131e-03  8.8979173e-03\n",
      "  2.0896459e-03  6.2489416e-03 -9.4457148e-03  9.5901238e-03\n",
      " -1.3483083e-03 -6.0521150e-03  2.9925345e-03 -4.5661093e-04\n",
      "  4.7064926e-03 -2.2830211e-03 -4.1378425e-03  2.2778988e-03\n",
      "  8.3543835e-03 -4.9956059e-03  2.6686788e-03 -7.9905549e-03\n",
      " -6.7733466e-03 -4.6766878e-04 -8.7677278e-03  2.7894378e-03\n",
      "  1.5985954e-03 -2.3196924e-03  5.0037908e-03  9.7487867e-03\n",
      "  8.4542679e-03 -1.8802249e-03  2.0581519e-03 -4.0036892e-03\n",
      " -8.2414057e-03  6.2779556e-03 -1.9491815e-03 -6.6620467e-04\n",
      " -1.7713320e-03 -4.5356657e-03  4.0617096e-03 -4.2701806e-03]\n",
      "[-2.5486641e-03  2.3561592e-04  1.4452442e-03  2.6856011e-03\n",
      " -1.1227793e-03 -3.5235325e-03  5.4872531e-04  1.9029006e-03\n",
      " -4.4953353e-03 -2.6140616e-03  4.5874007e-03 -4.0626354e-03\n",
      "  5.5763652e-03 -2.4598555e-03  3.4966853e-03  4.7586751e-03\n",
      " -1.1637497e-05 -4.9182614e-03  5.7722320e-04 -5.9966710e-03\n",
      " -3.1813656e-04  3.7652545e-03  3.8338264e-03 -4.0566497e-03\n",
      "  1.6569756e-03  7.9073501e-04 -3.5333664e-03 -1.1896053e-03\n",
      "  1.9180338e-03 -3.0042753e-03  3.6635958e-03 -2.4828440e-04\n",
      "  6.3345931e-03  8.9576310e-03 -7.5040292e-04  4.8170383e-03\n",
      "  8.7148038e-04  3.2358051e-03 -2.4443198e-04 -1.6160002e-03\n",
      "  1.7413264e-04  3.0536682e-03 -3.1881789e-03  5.5234949e-04\n",
      " -2.6911490e-03 -2.1257151e-03 -1.8051201e-03  2.9024708e-03\n",
      " -2.5781260e-03  1.5430705e-03 -9.3655195e-04  2.3701650e-03\n",
      " -2.9737090e-03  1.7509965e-03  3.7678722e-03 -3.4141277e-03\n",
      " -2.4261442e-03 -1.1771471e-03  5.9825461e-03 -1.3260938e-03\n",
      " -6.1758892e-03 -1.8700337e-05  7.0376103e-03 -3.5626371e-04\n",
      " -8.0174999e-03 -2.2521148e-04 -5.9839902e-03 -3.6632717e-03\n",
      " -1.5761844e-03 -1.6122911e-03 -1.0538842e-03  5.2527916e-03\n",
      " -5.4700999e-04  2.3737303e-03 -1.4545758e-03 -9.6845720e-04\n",
      "  4.5392537e-04 -6.9494857e-03 -1.9161301e-03  1.6816328e-03\n",
      "  2.7759287e-03 -4.2993994e-04  4.0008640e-03  5.6037665e-03\n",
      " -8.6215447e-04 -2.6252315e-05 -4.0250691e-03 -8.7435218e-04\n",
      "  3.4448868e-03  4.7565200e-03 -2.1833351e-03  3.7402231e-03\n",
      "  1.8884666e-03  3.9005482e-03  4.6796873e-03  3.6621545e-04\n",
      "  9.4409700e-04  2.4909987e-03  6.3656433e-03 -3.3955711e-03]\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "\n",
    "# Example dataset\n",
    "sentences = [['I', 'love', 'to', 'code'],\n",
    "             ['Machine', 'learning', 'is', 'exciting'],\n",
    "             ['Data', 'science', 'is', 'fun']]\n",
    "\n",
    "# Train the Word2Vec model\n",
    "model = Word2Vec(sentences, min_count=1)\n",
    "\n",
    "# Get the word embeddings\n",
    "word_embeddings = model.wv\n",
    "\n",
    "# Get the embedding for a specific word\n",
    "embedding = word_embeddings['code']\n",
    "\n",
    "# Print the embedding\n",
    "print(embedding)\n",
    "\n",
    "# Get the average embedding for a list of words\n",
    "word_list = ['I', 'love', 'to']\n",
    "embeddings = [word_embeddings[word] for word in word_list]\n",
    "avg_embedding = np.mean(embeddings, axis=0)\n",
    "\n",
    "# Print the average embedding\n",
    "print(avg_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YP3jgexY0hyg"
   },
   "source": [
    "Note that this is just a basic example, and you can further customize the training process and explore different parameters to optimize the embeddings for your specific use case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S69CKEtizyeQ"
   },
   "source": [
    "### 9.2 Dimensionality Reduction Techniques:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dEZWo4dgzyjj"
   },
   "source": [
    "Dimensionality reduction techniques, such as Principal Component Analysis (PCA) or t-SNE, can be used to reduce the dimensionality of high-dimensional data while preserving its important characteristics. These techniques are useful when dealing with large feature spaces or when trying to visualize and understand the underlying structure of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "id": "NRc2flwa0o1x",
    "outputId": "bfe55e5f-3123-41a4-9ae7-7917e835e8b0"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Apply PCA for dimensionality reduction\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "# Apply t-SNE for dimensionality reduction\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "X_tsne = tsne.fit_transform(X)\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "# Plot PCA results\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y)\n",
    "plt.title(\"PCA\")\n",
    "\n",
    "# Plot t-SNE results\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(X_tsne[:, 0], X_tsne[:, 1], c=y)\n",
    "plt.title(\"t-SNE\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aY8Pzrdq0o_B"
   },
   "source": [
    "Note that the choice of the number of components and other parameters may vary depending on the dataset and the specific use case. You can experiment with different parameter values and explore other dimensionality reduction techniques available in scikit-learn to find the most suitable approach for your data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BRfj6mjXzyso"
   },
   "source": [
    "### 9.3 Feature Importance and Selection with Tree-Based Models:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nKTaj8xpz3vw"
   },
   "source": [
    "Feature importance and selection with tree-based models is a process of evaluating the relevance and contribution of different features in a dataset when using tree-based algorithms. Tree-based models, such as decision trees, random forests, and gradient boosting machines, provide a natural way to assess feature importance based on how much they contribute to the model's predictive performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x6Yng5bM0-fr",
    "outputId": "0280a2a1-5b82-4e97-f71d-63f9ab15e026"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepal length (cm): 0.10809762464246378\n",
      "sepal width (cm): 0.030386812473242528\n",
      "petal length (cm): 0.43999397414456937\n",
      "petal width (cm): 0.4215215887397244\n",
      "Selected features:\n",
      "sepal length (cm)\n",
      "petal length (cm)\n",
      "petal width (cm)\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Random Forest classifier\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Retrieve feature importance scores\n",
    "importance_scores = rf.feature_importances_\n",
    "\n",
    "# Print the feature importance scores\n",
    "for feature, importance in zip(iris.feature_names, importance_scores):\n",
    "    print(f\"{feature}: {importance}\")\n",
    "\n",
    "# Select features based on a threshold\n",
    "threshold = 0.1\n",
    "selected_features = [feature for feature, importance in zip(iris.feature_names, importance_scores) if importance > threshold]\n",
    "\n",
    "# Print the selected features\n",
    "print(\"Selected features:\")\n",
    "for feature in selected_features:\n",
    "    print(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mDbSq44R0-pi"
   },
   "source": [
    "To select features based on a threshold, we define a threshold value and create a list of selected features by iterating over the feature names and importance scores. Features with importance scores greater than the threshold are added to the list.\n",
    "\n",
    "You can modify this code snippet according to your specific dataset and requirements. Additionally, you can experiment with different tree-based models, such as Gradient Boosting Machines (e.g., GradientBoostingClassifier), and adjust the parameters to achieve the desired feature selection results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RgEPyfe6z4GG"
   },
   "source": [
    "### 9.4 Automated Feature Engineering with AutoML:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZTkepXVcz68L"
   },
   "source": [
    "Automated Feature Engineering (AutoFE) is a process in Automated Machine Learning (AutoML) that aims to automatically generate and select effective features from raw data without the need for manual feature engineering. AutoFE uses algorithms and techniques to explore, transform, and combine the available data to create new features that enhance the predictive power of machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HhdVf0a-z7Hg",
    "outputId": "8777c7dd-d7d1-41ac-e77c-5d2da690cda2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 00m 05s]\n",
      "val_accuracy: 0.862500011920929\n",
      "\n",
      "Best val_accuracy So Far: 0.875\n",
      "Total elapsed time: 00h 00m 46s\n",
      "Epoch 1/10\n",
      "25/25 [==============================] - 1s 4ms/step - loss: 0.5245 - accuracy: 0.7962\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.3953 - accuracy: 0.8512\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.3527 - accuracy: 0.8687\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.3408 - accuracy: 0.8700\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.3220 - accuracy: 0.8712\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.3192 - accuracy: 0.8788\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.3102 - accuracy: 0.8712\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.3066 - accuracy: 0.8750\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2921 - accuracy: 0.8800\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.3000 - accuracy: 0.8763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3809 - accuracy: 0.8300\n",
      "Accuracy: 0.8299999833106995\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 10)]              0         \n",
      "                                                                 \n",
      " multi_category_encoding (Mu  (None, 10)               0         \n",
      " ltiCategoryEncoding)                                            \n",
      "                                                                 \n",
      " normalization (Normalizatio  (None, 10)               21        \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                352       \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               8448      \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 256)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      " classification_head_1 (Acti  (None, 1)                0         \n",
      " vation)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,078\n",
      "Trainable params: 9,057\n",
      "Non-trainable params: 21\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "import autokeras as ak\n",
    "\n",
    "# Generate a synthetic dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=10, random_state=42)\n",
    "\n",
    "# Convert the dataset to a pandas DataFrame\n",
    "df = pd.DataFrame(X, columns=[f\"feature_{i}\" for i in range(X.shape[1])])\n",
    "df[\"target\"] = y\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(\"target\", axis=1), df[\"target\"], test_size=0.2, random_state=42)\n",
    "\n",
    "# Define and fit the AutoML model\n",
    "automl = ak.StructuredDataClassifier(max_trials=10, overwrite=True)\n",
    "automl.fit(X_train, y_train, epochs=10)\n",
    "\n",
    "# Evaluate the AutoML model on the test set\n",
    "accuracy = automl.evaluate(X_test, y_test)[1]\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Get the best model and its architecture\n",
    "best_model = automl.export_model()\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x61gF4BAz7Rr"
   },
   "source": [
    "In this code, we first generate a synthetic dataset using the make_classification function and convert it to a pandas DataFrame. We then split the dataset into training and test sets using the train_test_split function.\n",
    "\n",
    "Next, we create an instance of the StructuredDataClassifier class from AutoKeras and fit it to the training data. The max_trials parameter controls the number of different model configurations to try during the search.\n",
    "\n",
    "After training the AutoML model, we evaluate its performance on the test set using the evaluate method. The accuracy is printed out as the evaluation result.\n",
    "\n",
    "And at the end, we export the best model obtained by AutoML using the export_model method, and print its summary to examine the model architecture and layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4fijxcrM59sx"
   },
   "source": [
    "These advanced feature engineering techniques require careful consideration, domain expertise, and experimentation. It's important to evaluate their impact on model performance and avoid overfitting or introducing unnecessary complexity. Successful application of these techniques can significantly enhance the predictive power and interpretability of machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b2rFFIjm5_KI"
   },
   "source": [
    "## 10. Evaluating the Impact of Feature Engineering:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ovwia0Pw5_OD"
   },
   "source": [
    "Evaluating the impact of feature engineering is crucial to assess the effectiveness of the engineered features in improving model performance. Here's an example code that demonstrates how to evaluate the impact of feature engineering using a machine learning model and cross-validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R6S2e79r8jIj",
    "outputId": "6eca9ac3-15cc-41b5-8f71-e75084a87fcd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy: 0.9560937742586555\n",
      "PCA Accuracy: 0.9490296537804689\n",
      "Accuracy Improvement: -0.0070641204781866085\n",
      "Improvement Percentage: -0.7388522620246166\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Load the Breast Cancer dataset\n",
    "cancer = load_breast_cancer()\n",
    "X = cancer.data\n",
    "y = cancer.target\n",
    "\n",
    "# Create a baseline model without feature engineering\n",
    "baseline_model = make_pipeline(StandardScaler(), RandomForestClassifier(random_state=42))\n",
    "\n",
    "# Evaluate the baseline model using cross-validation\n",
    "baseline_scores = cross_val_score(baseline_model, X, y, cv=5, scoring='accuracy')\n",
    "baseline_accuracy = baseline_scores.mean()\n",
    "\n",
    "print(\"Baseline Accuracy:\", baseline_accuracy)\n",
    "\n",
    "# Create a model with feature engineering (PCA)\n",
    "pca_model = make_pipeline(StandardScaler(), PCA(n_components=10), RandomForestClassifier(random_state=42))\n",
    "\n",
    "# Evaluate the PCA model using cross-validation\n",
    "pca_scores = cross_val_score(pca_model, X, y, cv=5, scoring='accuracy')\n",
    "pca_accuracy = pca_scores.mean()\n",
    "\n",
    "print(\"PCA Accuracy:\", pca_accuracy)\n",
    "\n",
    "# Calculate the improvement in accuracy\n",
    "accuracy_improvement = pca_accuracy - baseline_accuracy\n",
    "improvement_percentage = (accuracy_improvement / baseline_accuracy) * 100\n",
    "\n",
    "print(\"Accuracy Improvement:\", accuracy_improvement)\n",
    "print(\"Improvement Percentage:\", improvement_percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J74KapHI5_SJ"
   },
   "source": [
    "In this code, we use the \"Breast Cancer\" dataset as an example. We start by creating a baseline model without any feature engineering, using a pipeline that includes standard scaling and a random forest classifier. We evaluate the baseline model using cross-validation and calculate the accuracy as the performance metric.\n",
    "\n",
    "Next, we create a model with feature engineering using Principal Component Analysis (PCA). The pipeline includes standard scaling, PCA with 10 components, and a random forest classifier. We evaluate the PCA model using cross-validation and calculate the accuracy.\n",
    "\n",
    "At last, we calculate the improvement in accuracy between the baseline and PCA models. The improvement is measured as the difference in accuracy values, and the percentage improvement is also calculated.\n",
    "\n",
    "By comparing the accuracy values and the improvement percentage, we can assess the impact of the feature engineering technique (in this case, PCA) on the model performance. This evaluation process allows us to determine if the engineered features are beneficial and contribute to better predictions compared to the baseline model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eYWnlqip9cYs"
   },
   "source": [
    "## 11. Challenges and Best Practices in Feature Engineering:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YKopNHkP9mXt"
   },
   "source": [
    "Feature engineering plays a crucial role in building effective machine learning models. It involves transforming raw data into meaningful features that capture relevant information and improve model performance. However, feature engineering is not without its challenges. In this article, we will explore some common challenges faced in feature engineering and discuss best practices to overcome them.\n",
    "\n",
    "1. Insufficient domain knowledge: One of the primary challenges in feature engineering is understanding the domain and the underlying data. Without domain knowledge, it can be challenging to identify relevant features and create meaningful transformations. Best practice: Invest time in understanding the domain, consult domain experts, and perform exploratory data analysis to gain insights into the data and identify potential feature engineering opportunities.\n",
    "\n",
    "\n",
    "2. Handling missing data: Real-world datasets often contain missing values, which can pose challenges in feature engineering. Missing data can lead to biased or incomplete features if not handled properly. Best practice: Evaluate the missing data pattern and apply suitable techniques such as imputation or deletion to handle missing values. Consider creating additional features to indicate missingness if it carries valuable information.\n",
    "\n",
    "\n",
    "3. Dealing with categorical variables: Categorical variables require special treatment in feature engineering. One-hot encoding can quickly increase the dimensionality of the dataset, leading to the curse of dimensionality. Best practice: Explore techniques such as ordinal encoding, frequency encoding, or target encoding to represent categorical variables effectively. Consider applying dimensionality reduction techniques like PCA or feature hashing to reduce the dimensionality while preserving the information.\n",
    "\n",
    "\n",
    "4. Feature scaling: Different features may have different scales, which can affect the performance of certain machine learning algorithms. It is essential to scale features to a similar range to avoid bias in model training. Best practice: Apply appropriate feature scaling techniques like standardization (mean normalization) or normalization (min-max scaling) to bring features to a common scale.\n",
    "\n",
    "\n",
    "5. Curse of dimensionality: As the number of features increases, the size of the feature space grows exponentially, leading to the curse of dimensionality. This can result in increased computational complexity and overfitting. Best practice: Perform feature selection or dimensionality reduction techniques such as filter methods (e.g., correlation-based feature selection), wrapper methods (e.g., recursive feature elimination), or embedded methods (e.g., L1 regularization) to reduce the feature space and improve model performance.\n",
    "\n",
    "\n",
    "6. Time and computational constraints: In some scenarios, feature engineering can be time-consuming and computationally intensive, especially when dealing with large datasets or complex transformations. Best practice: Prioritize feature engineering techniques based on their potential impact and feasibility within the given time and resource constraints. Consider using parallel processing or distributed computing frameworks to speed up feature engineering tasks.\n",
    "\n",
    "\n",
    "7. Overfitting: While feature engineering aims to improve model performance, it is important to be cautious about overfitting. Creating too many complex features or incorporating noise can lead to overfitting and poor generalization to unseen data. Best practice: Regularly evaluate the performance of the model on validation or hold-out datasets to identify signs of overfitting. Use techniques like cross-validation and regularization to mitigate overfitting risks.\n",
    "\n",
    "\n",
    "8. Automation and reproducibility: As feature engineering involves numerous iterations and transformations, it is essential to ensure automation and reproducibility. Manually performing feature engineering steps can be error-prone and make it challenging to reproduce the results. Best practice: Leverage feature engineering libraries and frameworks that provide automation and version control capabilities. Document and organize the feature engineering steps to maintain reproducibility.\n",
    "\n",
    "\n",
    "In conclusion, feature engineering is a critical component of the machine learning pipeline, but it comes with its challenges. By understanding these challenges and following best practices, data scientists can effectively overcome them and create informative and impactful features for their models. Remember to always experiment, iterate, and evaluate the impact of feature engineering techniques on model performance to ensure optimal results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YUOX5WFM-IVo"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
